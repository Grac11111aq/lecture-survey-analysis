{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: ãƒ‡ãƒ¼ã‚¿å“è³ªç¢ºèªã¨åŸºç¤çµ±è¨ˆ\n",
    "\n",
    "## åˆ†æç›®çš„\n",
    "ANALYSIS_PLAN.md ã® Phase 1 ã«å¾“ã„ã€ä»¥ä¸‹ã‚’å®Ÿæ–½ï¼š\n",
    "1. ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆæ¬ æå€¤ã€å›ç­”ä¸€è²«æ€§ã€å¤–ã‚Œå€¤ï¼‰\n",
    "2. è¨˜è¿°çµ±è¨ˆé‡ã®ç®—å‡º\n",
    "3. Page_IDãƒãƒƒãƒãƒ³ã‚°ç¢ºèª\n",
    "\n",
    "## åˆ¤æ–­åŸºæº–\n",
    "- æ¬ æç‡>20%ã®é …ç›®ã¯è§£æã‹ã‚‰é™¤å¤–ã‚’æ¤œè¨\n",
    "- æ¥µç«¯ãªåã‚ŠãŒã‚ã‚‹é …ç›®ã¯å¤‰æ•°å¤‰æ›ã‚’æ¤œè¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "data_dir = '../data/analysis/'\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "before_df = pd.read_csv(data_dir + 'before_excel_compliant.csv')\n",
    "after_df = pd.read_csv(data_dir + 'after_excel_compliant.csv')\n",
    "comment_df = pd.read_csv(data_dir + 'comment.csv')\n",
    "\n",
    "print(\"=== ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº† ===\")\n",
    "print(f\"æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿: {before_df.shape}\")\n",
    "print(f\"æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿: {after_df.shape}\")\n",
    "print(f\"æ„Ÿæƒ³ãƒ‡ãƒ¼ã‚¿: {comment_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿æ§‹é€  ===\")\n",
    "print(before_df.info())\n",
    "print(\"\\n=== æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ ã‚µãƒ³ãƒ—ãƒ« ===\")\n",
    "display(before_df.head())\n",
    "\n",
    "print(\"\\n=== æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿æ§‹é€  ===\")\n",
    "print(after_df.info())\n",
    "print(\"\\n=== æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ ã‚µãƒ³ãƒ—ãƒ« ===\")\n",
    "display(after_df.head())\n",
    "\n",
    "print(\"\\n=== æ„Ÿæƒ³ãƒ‡ãƒ¼ã‚¿æ§‹é€  ===\")\n",
    "print(comment_df.info())\n",
    "print(\"\\n=== æ„Ÿæƒ³ãƒ‡ãƒ¼ã‚¿ ã‚µãƒ³ãƒ—ãƒ« ===\")\n",
    "display(comment_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Page_IDãƒãƒƒãƒãƒ³ã‚°ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page_IDã®ä¸€è‡´ç¢ºèª\n",
    "before_ids = set(before_df['Page_ID'])\n",
    "after_ids = set(after_df['Page_ID'])\n",
    "comment_ids = set(comment_df['page-ID']) if 'page-ID' in comment_df.columns else set(comment_df['Page_ID'])\n",
    "\n",
    "print(\"=== Page_ID ãƒãƒƒãƒãƒ³ã‚°åˆ†æ ===\")\n",
    "print(f\"æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ Page_IDæ•°: {len(before_ids)}\")\n",
    "print(f\"æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ Page_IDæ•°: {len(after_ids)}\")\n",
    "print(f\"æ„Ÿæƒ³ãƒ‡ãƒ¼ã‚¿ Page_IDæ•°: {len(comment_ids)}\")\n",
    "\n",
    "# å…±é€šã®Page_ID\n",
    "common_ids = before_ids & after_ids\n",
    "print(f\"\\nå‰å¾Œå…±é€š Page_IDæ•°: {len(common_ids)}\")\n",
    "print(f\"ãƒãƒƒãƒãƒ³ã‚°ç‡: {len(common_ids)/max(len(before_ids), len(after_ids))*100:.1f}%\")\n",
    "\n",
    "# ãƒãƒƒãƒãƒ³ã‚°ã—ãªã„Page_ID\n",
    "before_only = before_ids - after_ids\n",
    "after_only = after_ids - before_ids\n",
    "\n",
    "if before_only:\n",
    "    print(f\"\\næˆæ¥­å‰ã®ã¿: {sorted(before_only)}\")\n",
    "if after_only:\n",
    "    print(f\"æˆæ¥­å¾Œã®ã¿: {sorted(after_only)}\")\n",
    "\n",
    "# ã‚¯ãƒ©ã‚¹åˆ¥åˆ†å¸ƒ\n",
    "print(\"\\n=== ã‚¯ãƒ©ã‚¹åˆ¥åˆ†å¸ƒ ===\")\n",
    "print(\"æˆæ¥­å‰:\")\n",
    "print(before_df['class'].value_counts().sort_index())\n",
    "print(\"\\næˆæ¥­å¾Œ:\")\n",
    "print(after_df['class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æ¬ æå€¤åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, title):\n",
    "    \"\"\"\n",
    "    æ¬ æå€¤åˆ†æé–¢æ•°\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {title} æ¬ æå€¤åˆ†æ ===\")\n",
    "    \n",
    "    # æ¬ æå€¤ã®å‰²åˆ\n",
    "    missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    missing_counts = df.isnull().sum()\n",
    "    \n",
    "    missing_info = pd.DataFrame({\n",
    "        'æ¬ ææ•°': missing_counts,\n",
    "        'æ¬ æç‡(%)': missing_pct\n",
    "    })\n",
    "    \n",
    "    # æ¬ æå€¤ãŒã‚ã‚‹é …ç›®ã®ã¿è¡¨ç¤º\n",
    "    missing_info = missing_info[missing_info['æ¬ ææ•°'] > 0]\n",
    "    \n",
    "    if len(missing_info) > 0:\n",
    "        print(missing_info.sort_values('æ¬ æç‡(%)', ascending=False))\n",
    "        \n",
    "        # 20%ä»¥ä¸Šã®æ¬ æãŒã‚ã‚‹é …ç›®\n",
    "        high_missing = missing_info[missing_info['æ¬ æç‡(%)'] > 20]\n",
    "        if len(high_missing) > 0:\n",
    "            print(f\"\\nâš ï¸ 20%ä»¥ä¸Šæ¬ æã®é …ç›®: {list(high_missing.index)}\")\n",
    "    else:\n",
    "        print(\"æ¬ æå€¤ãªã—\")\n",
    "    \n",
    "    return missing_info\n",
    "\n",
    "# å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¬ æå€¤åˆ†æ\n",
    "before_missing = analyze_missing_values(before_df, \"æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿\")\n",
    "after_missing = analyze_missing_values(after_df, \"æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿\")\n",
    "comment_missing = analyze_missing_values(comment_df, \"æ„Ÿæƒ³ãƒ‡ãƒ¼ã‚¿\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¬ æå€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "sns.heatmap(before_df.isnull(), ax=axes[0], cbar=True, yticklabels=False, cmap='viridis')\n",
    "axes[0].set_title('æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ æ¬ æå€¤ãƒ‘ã‚¿ãƒ¼ãƒ³')\n",
    "axes[0].set_xlabel('ã‚«ãƒ©ãƒ ')\n",
    "\n",
    "# æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "sns.heatmap(after_df.isnull(), ax=axes[1], cbar=True, yticklabels=False, cmap='viridis')\n",
    "axes[1].set_title('æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ æ¬ æå€¤ãƒ‘ã‚¿ãƒ¼ãƒ³')\n",
    "axes[1].set_xlabel('ã‚«ãƒ©ãƒ ')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Q1é …ç›®ï¼ˆæ°´æº¶æ¶²èªè­˜ï¼‰ã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1é …ç›®ã®åˆ†æï¼ˆæˆæ¥­å‰å¾Œå…±é€šï¼‰\n",
    "q1_cols_before = [col for col in before_df.columns if col.startswith('Q1_')]\n",
    "q1_cols_after = [col for col in after_df.columns if col.startswith('Q1_')]\n",
    "\n",
    "print(\"=== Q1é …ç›®ï¼ˆæ°´æº¶æ¶²èªè­˜ï¼‰åˆ†æ ===\")\n",
    "print(f\"æˆæ¥­å‰ Q1é …ç›®: {q1_cols_before}\")\n",
    "print(f\"æˆæ¥­å¾Œ Q1é …ç›®: {q1_cols_after}\")\n",
    "\n",
    "# å‰å¾Œã§å¯¾å¿œã™ã‚‹é …ç›®ã®ç¢ºèª\n",
    "def standardize_q1_columns(before_cols, after_cols):\n",
    "    \"\"\"\n",
    "    Q1é …ç›®ã®å¯¾å¿œé–¢ä¿‚ã‚’ç¢ºèªãƒ»æ¨™æº–åŒ–\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Q1é …ç›®å¯¾å¿œé–¢ä¿‚ ===\")\n",
    "    \n",
    "    # ç‰©è³ªåã‚’æŠ½å‡ºã—ã¦å¯¾å¿œä»˜ã‘\n",
    "    substances = ['Saltwater', 'Sugarwater', 'Muddywater', 'Ink', 'MisoSoup', 'SoySauce']\n",
    "    \n",
    "    correspondence = {}\n",
    "    for substance in substances:\n",
    "        before_col = None\n",
    "        after_col = None\n",
    "        \n",
    "        for col in before_cols:\n",
    "            if substance in col:\n",
    "                before_col = col\n",
    "                break\n",
    "        \n",
    "        for col in after_cols:\n",
    "            if substance in col:\n",
    "                after_col = col\n",
    "                break\n",
    "        \n",
    "        if before_col and after_col:\n",
    "            correspondence[substance] = {'before': before_col, 'after': after_col}\n",
    "            print(f\"{substance}: {before_col} â†” {after_col}\")\n",
    "    \n",
    "    return correspondence\n",
    "\n",
    "q1_correspondence = standardize_q1_columns(q1_cols_before, q1_cols_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1é …ç›®ã®è¨˜è¿°çµ±è¨ˆ\n",
    "def analyze_q1_responses(correspondence, before_df, after_df):\n",
    "    \"\"\"\n",
    "    Q1é …ç›®ã®å›ç­”åˆ†æ\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Q1é …ç›® æ­£ç­”ç‡åˆ†æ ===\")\n",
    "    \n",
    "    # æ­£ç­”åŸºæº–ï¼ˆä»®å®š: é£Ÿå¡©æ°´ãƒ»ç ‚ç³–æ°´ãƒ»å‘³å™Œæ±ãƒ»é†¤æ²¹=Trueã€æ³¥æ°´ãƒ»å¢¨æ±=Falseï¼‰\n",
    "    correct_answers = {\n",
    "        'Saltwater': True,\n",
    "        'Sugarwater': True, \n",
    "        'Muddywater': False,\n",
    "        'Ink': False,\n",
    "        'MisoSoup': True,\n",
    "        'SoySauce': True\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for substance, cols in correspondence.items():\n",
    "        before_col = cols['before']\n",
    "        after_col = cols['after']\n",
    "        correct = correct_answers.get(substance)\n",
    "        \n",
    "        # æˆæ¥­å‰æ­£ç­”ç‡\n",
    "        before_correct = (before_df[before_col] == correct).sum()\n",
    "        before_total = before_df[before_col].notna().sum()\n",
    "        before_rate = before_correct / before_total * 100 if before_total > 0 else 0\n",
    "        \n",
    "        # æˆæ¥­å¾Œæ­£ç­”ç‡\n",
    "        after_correct = (after_df[after_col] == correct).sum()\n",
    "        after_total = after_df[after_col].notna().sum()\n",
    "        after_rate = after_correct / after_total * 100 if after_total > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'ç‰©è³ª': substance,\n",
    "            'æ­£ç­”': correct,\n",
    "            'æˆæ¥­å‰_æ­£ç­”æ•°': before_correct,\n",
    "            'æˆæ¥­å‰_ç·æ•°': before_total,\n",
    "            'æˆæ¥­å‰_æ­£ç­”ç‡': round(before_rate, 1),\n",
    "            'æˆæ¥­å¾Œ_æ­£ç­”æ•°': after_correct,\n",
    "            'æˆæ¥­å¾Œ_ç·æ•°': after_total,\n",
    "            'æˆæ¥­å¾Œ_æ­£ç­”ç‡': round(after_rate, 1),\n",
    "            'å¤‰åŒ–': round(after_rate - before_rate, 1)\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    display(results_df)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "q1_results = analyze_q1_responses(q1_correspondence, before_df, after_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. è¨˜è¿°çµ±è¨ˆé‡ã®ç®—å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptive_stats(df, title):\n",
    "    \"\"\"\n",
    "    è¨˜è¿°çµ±è¨ˆé‡ã®ç®—å‡º\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {title} è¨˜è¿°çµ±è¨ˆé‡ ===\")\n",
    "    \n",
    "    # æ•°å€¤å¤‰æ•°ã®è¨˜è¿°çµ±è¨ˆ\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"\\n--- æ•°å€¤å¤‰æ•° ---\")\n",
    "        stats_df = df[numeric_cols].describe()\n",
    "        display(stats_df)\n",
    "        \n",
    "        # æ­ªåº¦ãƒ»å°–åº¦ã®è¨ˆç®—\n",
    "        skew_kurt = pd.DataFrame({\n",
    "            'æ­ªåº¦': df[numeric_cols].skew(),\n",
    "            'å°–åº¦': df[numeric_cols].kurtosis()\n",
    "        })\n",
    "        print(\"\\n--- æ­ªåº¦ãƒ»å°–åº¦ ---\")\n",
    "        display(skew_kurt)\n",
    "    \n",
    "    # ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®åº¦æ•°åˆ†å¸ƒ\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'bool']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(\"\\n--- ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°åº¦æ•°åˆ†å¸ƒ ---\")\n",
    "        for col in categorical_cols:\n",
    "            if col != 'Page_ID':  # Page_IDã¯é™¤å¤–\n",
    "                print(f\"\\n{col}:\")\n",
    "                print(df[col].value_counts(dropna=False))\n",
    "\n",
    "# å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨˜è¿°çµ±è¨ˆ\n",
    "calculate_descriptive_stats(before_df, \"æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿\")\n",
    "calculate_descriptive_stats(after_df, \"æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1æ­£ç­”ç‡ã®å¯è¦–åŒ–\n",
    "fig = go.Figure()\n",
    "\n",
    "# æˆæ¥­å‰å¾Œã®æ­£ç­”ç‡æ¯”è¼ƒ\n",
    "substances = q1_results['ç‰©è³ª'].tolist()\n",
    "before_rates = q1_results['æˆæ¥­å‰_æ­£ç­”ç‡'].tolist()\n",
    "after_rates = q1_results['æˆæ¥­å¾Œ_æ­£ç­”ç‡'].tolist()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='æˆæ¥­å‰',\n",
    "    x=substances,\n",
    "    y=before_rates,\n",
    "    text=[f'{rate}%' for rate in before_rates],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='æˆæ¥­å¾Œ',\n",
    "    x=substances,\n",
    "    y=after_rates,\n",
    "    text=[f'{rate}%' for rate in after_rates],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Q1é …ç›® æˆæ¥­å‰å¾Œæ­£ç­”ç‡æ¯”è¼ƒ',\n",
    "    xaxis_title='ç‰©è³ª',\n",
    "    yaxis_title='æ­£ç­”ç‡ (%)',\n",
    "    barmode='group',\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡é …ç›®åˆ†å¸ƒ\n",
    "if 'Q4_ExperimentInterestRating' in after_df.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Q4: å®Ÿé¨“èˆˆå‘³åº¦\n",
    "    q4_counts = after_df['Q4_ExperimentInterestRating'].value_counts().sort_index()\n",
    "    axes[0,0].bar(q4_counts.index, q4_counts.values)\n",
    "    axes[0,0].set_title('Q4: å®Ÿé¨“ã¸ã®èˆˆå‘³åº¦')\n",
    "    axes[0,0].set_xlabel('è©•ä¾¡ (1:é¢ç™½ããªã„ - 4:ã¨ã¦ã‚‚é¢ç™½ã„)')\n",
    "    axes[0,0].set_ylabel('äººæ•°')\n",
    "    \n",
    "    # Q5: æ–°ã—ã„å­¦ã³\n",
    "    if 'Q5_NewLearningsRating' in after_df.columns:\n",
    "        q5_counts = after_df['Q5_NewLearningsRating'].value_counts().sort_index()\n",
    "        axes[0,1].bar(q5_counts.index, q5_counts.values)\n",
    "        axes[0,1].set_title('Q5: æ–°ã—ã„å­¦ã³')\n",
    "        axes[0,1].set_xlabel('è©•ä¾¡')\n",
    "        axes[0,1].set_ylabel('äººæ•°')\n",
    "    \n",
    "    # Q6: ç†è§£åº¦\n",
    "    if 'Q6_DissolvingUnderstandingRating' in after_df.columns:\n",
    "        q6_counts = after_df['Q6_DissolvingUnderstandingRating'].value_counts().sort_index()\n",
    "        axes[1,0].bar(q6_counts.index, q6_counts.values)\n",
    "        axes[1,0].set_title('Q6: ç†è§£åº¦')\n",
    "        axes[1,0].set_xlabel('è©•ä¾¡ (1:ã‚ã‹ã‚‰ãªã„ - 4:ã‚ˆãã‚ã‹ã£ãŸ)')\n",
    "        axes[1,0].set_ylabel('äººæ•°')\n",
    "    \n",
    "    # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ\n",
    "    class_counts = after_df['class'].value_counts().sort_index()\n",
    "    axes[1,1].bar(class_counts.index, class_counts.values)\n",
    "    axes[1,1].set_title('ã‚¯ãƒ©ã‚¹åˆ¥å›ç­”è€…æ•°')\n",
    "    axes[1,1].set_xlabel('ã‚¯ãƒ©ã‚¹')\n",
    "    axes[1,1].set_ylabel('äººæ•°')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ãƒ‡ãƒ¼ã‚¿å“è³ªã‚µãƒãƒªãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 1 ãƒ‡ãƒ¼ã‚¿å“è³ªç¢ºèª çµæœã‚µãƒãƒªãƒ¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nğŸ“Š ãƒ‡ãƒ¼ã‚¿è¦æ¨¡:\")\n",
    "print(f\"ãƒ»æˆæ¥­å‰å›ç­”è€…: {len(before_df)}å\")\n",
    "print(f\"ãƒ»æˆæ¥­å¾Œå›ç­”è€…: {len(after_df)}å\")\n",
    "print(f\"ãƒ»å‰å¾Œãƒãƒƒãƒãƒ³ã‚°: {len(common_ids)}å ({len(common_ids)/max(len(before_ids), len(after_ids))*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ” ãƒ‡ãƒ¼ã‚¿å“è³ª:\")\n",
    "# æ¬ æå€¤ãŒ20%ä»¥ä¸Šã®é …ç›®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "high_missing_before = before_missing[before_missing['æ¬ æç‡(%)'] > 20] if len(before_missing) > 0 else pd.DataFrame()\n",
    "high_missing_after = after_missing[after_missing['æ¬ æç‡(%)'] > 20] if len(after_missing) > 0 else pd.DataFrame()\n",
    "\n",
    "if len(high_missing_before) == 0 and len(high_missing_after) == 0:\n",
    "    print(\"ãƒ»20%ä»¥ä¸Šã®æ¬ æé …ç›®: ãªã— âœ…\")\n",
    "else:\n",
    "    print(\"ãƒ»20%ä»¥ä¸Šã®æ¬ æé …ç›®: ã‚ã‚Š âš ï¸\")\n",
    "    if len(high_missing_before) > 0:\n",
    "        print(f\"  æˆæ¥­å‰: {list(high_missing_before.index)}\")\n",
    "    if len(high_missing_after) > 0:\n",
    "        print(f\"  æˆæ¥­å¾Œ: {list(high_missing_after.index)}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ä¸»è¦çµæœ:\")\n",
    "print(f\"ãƒ»Q1æ°´æº¶æ¶²èªè­˜é …ç›®: {len(q1_correspondence)}é …ç›®ã§å‰å¾Œæ¯”è¼ƒå¯èƒ½\")\n",
    "if len(q1_results) > 0:\n",
    "    avg_change = q1_results['å¤‰åŒ–'].mean()\n",
    "    print(f\"ãƒ»å¹³å‡æ­£ç­”ç‡å¤‰åŒ–: {avg_change:.1f}ãƒã‚¤ãƒ³ãƒˆ\")\n",
    "    positive_changes = (q1_results['å¤‰åŒ–'] > 0).sum()\n",
    "    print(f\"ãƒ»æ”¹å–„é …ç›®æ•°: {positive_changes}/{len(q1_results)}é …ç›®\")\n",
    "\n",
    "print(f\"\\nâœ… Phase 1 å®Œäº† - Phase 2 (çµ±è¨ˆçš„æ¤œè¨¼) ã«é€²è¡Œå¯èƒ½\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}