# æœ‰åŠ¹ãªåˆ†æçµæœã®æŠ½å‡ºã‚¬ã‚¤ãƒ‰

**ç›®çš„**: åˆå›åˆ†æã‹ã‚‰æœ‰åŠ¹ãªéƒ¨åˆ†ã‚’æŠ½å‡ºã—ã€ä¿®æ­£ç‰ˆã¨çµ±åˆã™ã‚‹ãŸã‚ã®æŠ€è¡“ã‚¬ã‚¤ãƒ‰

## ğŸ“‚ çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ 

```
outputs/
â”œâ”€â”€ phase1_detailed_results.json    # âœ… éƒ¨åˆ†çš„ã«æœ‰åŠ¹
â”œâ”€â”€ phase2_detailed_results.json    # âŒ ç„¡åŠ¹ï¼ˆãƒšã‚¢ãƒ‡ãƒ¼ã‚¿å‰æï¼‰
â”œâ”€â”€ phase2_revised_results.json     # âœ… æ–°è¦ä½œæˆï¼ˆç‹¬ç«‹ç¾¤æ¯”è¼ƒï¼‰
â”œâ”€â”€ phase3_detailed_results.json    # âœ… éƒ¨åˆ†çš„ã«æœ‰åŠ¹
â”œâ”€â”€ phase4_detailed_results.json    # âœ… ã»ã¼æœ‰åŠ¹
â””â”€â”€ phase5_integrated_results.json  # âŒ å†æ§‹ç¯‰å¿…è¦
```

## ğŸ” Phaseåˆ¥æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚³ãƒ¼ãƒ‰

### Phase 1: åŸºç¤çµ±è¨ˆã®æŠ½å‡º

```python
import json
from pathlib import Path

def extract_valid_phase1_results():
    """Phase 1ã‹ã‚‰æœ‰åŠ¹ãªçµæœã‚’æŠ½å‡º"""
    
    with open('outputs/phase1_detailed_results.json', 'r', encoding='utf-8') as f:
        phase1_data = json.load(f)
    
    valid_results = {
        'data_quality': {
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯çµæœï¼ˆã™ã¹ã¦æœ‰åŠ¹ï¼‰
            'missing_analysis': phase1_data['quality_check'],
            'sample_sizes': {
                'before': phase1_data['basic_statistics']['class_analysis']['æˆæ¥­å‰']['total'],
                'after': phase1_data['basic_statistics']['class_analysis']['æˆæ¥­å¾Œ']['total']
            }
        },
        'descriptive_statistics': {
            # æˆæ¥­å‰å¾Œåˆ¥ã€…ã®è¨˜è¿°çµ±è¨ˆï¼ˆæœ‰åŠ¹ï¼‰
            'before': {
                'q1_rates': phase1_data['basic_statistics']['q1_analysis']['before'],
                'q3_rates': phase1_data['basic_statistics']['q3_analysis']['before']
            },
            'after': {
                'q1_rates': phase1_data['basic_statistics']['q1_analysis']['after'],
                'q3_rates': phase1_data['basic_statistics']['q3_analysis']['after'],
                'evaluation_stats': phase1_data['basic_statistics']['evaluation_analysis']
            }
        },
        'class_distribution': phase1_data['basic_statistics']['class_analysis']
    }
    
    # âŒ é™¤å¤–ã™ã¹ãå†…å®¹
    # - q1_analysis['comparison'] ï¼ˆå€‹äººã®å¤‰åŒ–ã‚’å‰æï¼‰
    # - q3_analysis['comparison'] ï¼ˆå€‹äººã®å¤‰åŒ–ã‚’å‰æï¼‰
    
    return valid_results
```

### Phase 3: ã‚¯ãƒ©ã‚¹é–“åˆ†æã®æŠ½å‡º

```python
def extract_valid_phase3_results():
    """Phase 3ã‹ã‚‰æœ‰åŠ¹ãªçµæœã‚’æŠ½å‡º"""
    
    with open('outputs/phase3_detailed_results.json', 'r', encoding='utf-8') as f:
        phase3_data = json.load(f)
    
    valid_results = {
        'class_comparisons': {
            # å„æ™‚ç‚¹ã§ã®ã‚¯ãƒ©ã‚¹é–“æ¯”è¼ƒï¼ˆæœ‰åŠ¹ï¼‰
            'before_analysis': phase3_data['class_comparison']['before_analysis'],
            'after_analysis': phase3_data['class_comparison']['after_analysis']
            # âŒ 'change_analysis'ã¯é™¤å¤–ï¼ˆå¤‰åŒ–é‡åˆ†æã®ãŸã‚ï¼‰
        },
        'prediction_model': {
            # æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã®ã¿ã®äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆæœ‰åŠ¹ï¼‰
            'logistic_regression': phase3_data['factors_analysis']['logistic_regression']
            # æ³¨: multiple_regressionã¯è¦ç¢ºèªï¼ˆå¤‰åŒ–é‡ã‚’ä½¿ç”¨ã—ã¦ã„ãªã‘ã‚Œã°æœ‰åŠ¹ï¼‰
        }
    }
    
    return valid_results
```

### Phase 4: ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®æŠ½å‡º

```python
def extract_valid_phase4_results():
    """Phase 4ã‹ã‚‰æœ‰åŠ¹ãªçµæœã‚’æŠ½å‡ºï¼ˆè§£é‡ˆä¿®æ­£ä»˜ãï¼‰"""
    
    with open('outputs/phase4_detailed_results.json', 'r', encoding='utf-8') as f:
        phase4_data = json.load(f)
    
    valid_results = phase4_data.copy()  # ã»ã¼ã™ã¹ã¦æœ‰åŠ¹
    
    # Q2æ¯”è¼ƒã®è§£é‡ˆã‚’ä¿®æ­£
    if 'frequency_analysis' in valid_results and 'q2_comparison' in valid_results['frequency_analysis']:
        q2_comp = valid_results['frequency_analysis']['q2_comparison']
        
        # è§£é‡ˆã®ä¿®æ­£ã‚’è¿½è¨˜
        q2_comp['interpretation_note'] = (
            "æ³¨æ„: ã“ã‚Œã¯æˆæ¥­å‰ç¾¤ã¨æˆæ¥­å¾Œç¾¤ã®èªå½™ä½¿ç”¨ã®å·®ç•°ã‚’ç¤ºã™ã‚‚ã®ã§ã‚ã‚Šã€"
            "å€‹äººã®èªå½™å¤‰åŒ–ã§ã¯ãªã„ã€‚"
        )
        
        # ç”¨èªã®ä¿®æ­£
        if 'new_words' in q2_comp:
            q2_comp['words_unique_to_after_group'] = q2_comp.pop('new_words')
        if 'disappeared_words' in q2_comp:
            q2_comp['words_unique_to_before_group'] = q2_comp.pop('disappeared_words')
    
    return valid_results
```

## ğŸ”— çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€çµ‚çµ±åˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç‹¬ç«‹ç¾¤æ¯”è¼ƒã«åŸºã¥ãä¿®æ­£ç‰ˆ
"""

import json
from pathlib import Path
import pandas as pd
import numpy as np

class FinalIntegratedAnalyzer:
    def __init__(self):
        self.results_dir = Path("outputs")
        self.integrated_results = {}
        
    def load_all_valid_results(self):
        """ã™ã¹ã¦ã®æœ‰åŠ¹ãªçµæœã‚’èª­ã¿è¾¼ã¿"""
        
        # Phase 1ï¼ˆæœ‰åŠ¹éƒ¨åˆ†ï¼‰
        self.integrated_results['phase1'] = extract_valid_phase1_results()
        
        # Phase 2ï¼ˆä¿®æ­£ç‰ˆï¼‰
        with open(self.results_dir / "phase2_revised_results.json", 'r', encoding='utf-8') as f:
            self.integrated_results['phase2'] = json.load(f)
        
        # Phase 3ï¼ˆæœ‰åŠ¹éƒ¨åˆ†ï¼‰
        self.integrated_results['phase3'] = extract_valid_phase3_results()
        
        # Phase 4ï¼ˆè§£é‡ˆä¿®æ­£æ¸ˆã¿ï¼‰
        self.integrated_results['phase4'] = extract_valid_phase4_results()
        
    def create_final_report(self):
        """æœ€çµ‚çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ"""
        
        report = {
            'metadata': {
                'analysis_type': 'ç‹¬ç«‹ç¾¤æ¯”è¼ƒåˆ†æ',
                'limitation': 'Page_IDã¯å€‹äººè­˜åˆ¥å­ã§ã¯ãªã„ãŸã‚ã€å€‹äººè¿½è·¡ã¯ä¸å¯èƒ½',
                'interpretation_note': 'ç¾¤é–“å·®ã‚’ç¤ºã™ã‚‚ã®ã§ã‚ã‚Šã€å€‹äººã®å¤‰åŒ–ã§ã¯ãªã„'
            },
            'results': self.integrated_results,
            'conclusions': self.synthesize_conclusions()
        }
        
        return report
        
    def synthesize_conclusions(self):
        """çµè«–ã®çµ±åˆï¼ˆæ…é‡ãªè§£é‡ˆï¼‰"""
        conclusions = {
            'group_differences': [],
            'educational_implications': [],
            'limitations': [],
            'future_research': []
        }
        
        # å…·ä½“çš„ãªçµè«–ã®æ§‹ç¯‰...
        
        return conclusions
```

## âš ï¸ çµ±åˆæ™‚ã®æ³¨æ„äº‹é …

### 1. ç”¨èªã®çµ±ä¸€
| æ—§ç”¨èª | æ–°ç”¨èª |
|--------|--------|
| å¤‰åŒ– | ç¾¤é–“å·® |
| å‘ä¸Š/æ”¹å–„ | æˆæ¥­å¾Œç¾¤ã§é«˜ã„ |
| æ‚ªåŒ–/ä½ä¸‹ | æˆæ¥­å¾Œç¾¤ã§ä½ã„ |
| åŠ¹æœ | å·®ç•° |

### 2. å›³è¡¨ã®ä¿®æ­£
- ã‚¿ã‚¤ãƒˆãƒ«ã«ã€Œç‹¬ç«‹ç¾¤æ¯”è¼ƒã€ã‚’æ˜è¨˜
- è»¸ãƒ©ãƒ™ãƒ«ã‚’ã€ŒBefore Groupã€ã€ŒAfter Groupã€ã«
- ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã«è§£é‡ˆã®é™ç•Œã‚’è¨˜è¼‰

### 3. çµ±è¨ˆé‡ã®è¡¨è¨˜
- å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š â†’ Mann-Whitney Uæ¤œå®š
- McNemaræ¤œå®š â†’ Ï‡Â²æ¤œå®š
- å€‹äººãƒ¬ãƒ™ãƒ«ã®ç›¸é–¢ â†’ ç¾¤ãƒ¬ãƒ™ãƒ«ã®é–¢é€£

## ğŸ“Š æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] ã™ã¹ã¦ã®ã€Œãƒšã‚¢ã€ã€Œå¯¾å¿œã€ã¨ã„ã†ç”¨èªã‚’å‰Šé™¤
- [ ] ã€Œå¤‰åŒ–ã€ã‚’ã€Œå·®ç•°ã€ã«ç½®æ›
- [ ] çµ±è¨ˆæ‰‹æ³•ãŒç‹¬ç«‹ç¾¤ç”¨ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèª
- [ ] è§£é‡ˆã«å› æœé–¢ä¿‚ã‚’ç¤ºå”†ã™ã‚‹è¡¨ç¾ãŒãªã„ã‹ç¢ºèª
- [ ] é™ç•Œäº‹é …ãŒæ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª

---

ã“ã®ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦ã€æ¬¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§åŠ¹ç‡çš„ã«æœ‰åŠ¹ãªçµæœã‚’æŠ½å‡ºãƒ»çµ±åˆã™ã‚‹ã“ã¨ã€‚