#!/usr/bin/env python3
"""
Phase 2: æ•™è‚²åŠ¹æœã®çµ±è¨ˆçš„æ¤œè¨¼
ANALYSIS_PLAN.md ã® Phase 2 ã«å¾“ã„å®Ÿæ–½:
- McNemaræ¤œå®šï¼ˆå¯¾å¿œã®ã‚ã‚‹äºŒé …ãƒ‡ãƒ¼ã‚¿ï¼‰
- å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šï¼ˆç·åˆã‚¹ã‚³ã‚¢ï¼‰
- åŠ¹æœé‡ç®—å‡ºï¼ˆCohen's dï¼‰
- å¤šé‡æ¯”è¼ƒè£œæ­£
- ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãƒ»æ¤œå‡ºåŠ›åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
from scipy.stats import mcnemar
import pingouin as pg
from statsmodels.stats.contingency_tables import mcnemar as sm_mcnemar
from statsmodels.stats.power import ttest_power
from statsmodels.stats.multitest import multipletests
import warnings
import os

warnings.filterwarnings('ignore')

class Phase2StatisticalTesting:
    def __init__(self, data_dir='data/analysis/'):
        self.data_dir = data_dir
        self.before_df = None
        self.after_df = None
        self.matched_df = None
        self.significance_level = 0.05
        
    def load_and_prepare_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"""
        print("=== Phase 2: ãƒ‡ãƒ¼ã‚¿æº–å‚™ ===")
        
        self.before_df = pd.read_csv(os.path.join(self.data_dir, 'before_excel_compliant.csv'))
        self.after_df = pd.read_csv(os.path.join(self.data_dir, 'after_excel_compliant.csv'))
        
        # Page_IDã§ãƒãƒƒãƒãƒ³ã‚°
        matched_before = self.before_df.set_index('Page_ID')
        matched_after = self.after_df.set_index('Page_ID')
        
        # å…±é€šã®Page_IDã®ã¿æŠ½å‡º
        common_ids = matched_before.index.intersection(matched_after.index)
        
        self.matched_df = pd.DataFrame(index=common_ids)
        
        # Q1é …ç›®ã®å¯¾å¿œé–¢ä¿‚
        q1_mapping = {
            'Saltwater': ('Q1_Saltwater_Response', 'Q1_Saltwater'),
            'Sugarwater': ('Q1_Sugarwater_Response', 'Q1_Sugarwater'),
            'Muddywater': ('Q1_Muddywater_Response', 'Q1_Muddywater'),
            'Ink': ('Q1_Ink_Response', 'Q1_Ink'),
            'MisoSoup': ('Q1_MisoSoup_Response', 'Q1_MisoSoup'),
            'SoySauce': ('Q1_SoySauce_Response', 'Q1_SoySauce')
        }
        
        # æ­£ç­”åŸºæº–
        self.correct_answers = {
            'Saltwater': True,
            'Sugarwater': True,
            'Muddywater': False,
            'Ink': False,
            'MisoSoup': True,
            'SoySauce': True
        }
        
        # ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        for substance, (before_col, after_col) in q1_mapping.items():
            self.matched_df[f'{substance}_before'] = matched_before.loc[common_ids, before_col]
            self.matched_df[f'{substance}_after'] = matched_after.loc[common_ids, after_col]
            
            # æ­£ç­”ãƒ•ãƒ©ã‚°
            correct = self.correct_answers[substance]
            self.matched_df[f'{substance}_before_correct'] = (self.matched_df[f'{substance}_before'] == correct)
            self.matched_df[f'{substance}_after_correct'] = (self.matched_df[f'{substance}_after'] == correct)
        
        # ã‚¯ãƒ©ã‚¹æƒ…å ±
        self.matched_df['class'] = matched_before.loc[common_ids, 'class']
        
        print(f"ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: {len(self.matched_df)}ä»¶")
        print()\n        \n    def mcnemar_test_analysis(self):\n        \"\"\"McNemaræ¤œå®šã«ã‚ˆã‚‹å‰å¾Œæ¯”è¼ƒ\"\"\"\n        print(\"=== McNemaræ¤œå®šã«ã‚ˆã‚‹å‰å¾Œæ¯”è¼ƒ ===\")\n        \n        substances = list(self.correct_answers.keys())\n        results = []\n        \n        for substance in substances:\n            before_col = f'{substance}_before_correct'\n            after_col = f'{substance}_after_correct'\n            \n            # æ¬ æå€¤ã‚’é™¤å¤–\n            valid_mask = self.matched_df[before_col].notna() & self.matched_df[after_col].notna()\n            before_data = self.matched_df.loc[valid_mask, before_col]\n            after_data = self.matched_df.loc[valid_mask, after_col]\n            \n            if len(before_data) == 0:\n                continue\n                \n            # åˆ†å‰²è¡¨ä½œæˆ\n            # True/True, True/False, False/True, False/False\n            tt = ((before_data == True) & (after_data == True)).sum()\n            tf = ((before_data == True) & (after_data == False)).sum()\n            ft = ((before_data == False) & (after_data == True)).sum()\n            ff = ((before_data == False) & (after_data == False)).sum()\n            \n            contingency_table = np.array([[tt, tf], [ft, ff]])\n            \n            # McNemaræ¤œå®š\n            if tf + ft > 0:  # å¤‰åŒ–ãŒã‚ã‚‹å ´åˆã®ã¿\n                try:\n                    result = mcnemar(contingency_table, exact=True)\n                    p_value = result.pvalue\n                    statistic = result.statistic\n                except:\n                    # exactãŒå¤±æ•—ã—ãŸå ´åˆã¯è¿‘ä¼¼ç‰ˆ\n                    result = mcnemar(contingency_table, exact=False, correction=True)\n                    p_value = result.pvalue\n                    statistic = result.statistic\n            else:\n                p_value = 1.0\n                statistic = 0.0\n            \n            # æ­£ç­”ç‡è¨ˆç®—\n            before_rate = before_data.mean() * 100\n            after_rate = after_data.mean() * 100\n            change = after_rate - before_rate\n            \n            # åŠ¹æœé‡ï¼ˆã‚ªãƒƒã‚ºæ¯”ï¼‰\n            if tf > 0 and ft > 0:\n                odds_ratio = ft / tf\n            elif tf == 0 and ft > 0:\n                odds_ratio = float('inf')\n            elif tf > 0 and ft == 0:\n                odds_ratio = 0.0\n            else:\n                odds_ratio = 1.0\n            \n            results.append({\n                'ç‰©è³ª': substance,\n                'N': len(before_data),\n                'æˆæ¥­å‰æ­£ç­”ç‡': round(before_rate, 1),\n                'æˆæ¥­å¾Œæ­£ç­”ç‡': round(after_rate, 1),\n                'å¤‰åŒ–': round(change, 1),\n                'æ”¹å–„â†’æ‚ªåŒ–': tf,\n                'æ‚ªåŒ–â†’æ”¹å–„': ft,\n                'McNemarçµ±è¨ˆé‡': round(statistic, 3),\n                'på€¤': round(p_value, 4),\n                'ã‚ªãƒƒã‚ºæ¯”': round(odds_ratio, 3) if odds_ratio != float('inf') else 'inf'\n            })\n        \n        results_df = pd.DataFrame(results)\n        print(results_df.to_string(index=False))\n        \n        # å¤šé‡æ¯”è¼ƒè£œæ­£\n        p_values = results_df['på€¤'].values\n        rejected, p_corrected, alpha_sidak, alpha_bonf = multipletests(\n            p_values, alpha=self.significance_level, method='bonferroni'\n        )\n        \n        results_df['på€¤_è£œæ­£'] = np.round(p_corrected, 4)\n        results_df['æœ‰æ„'] = rejected\n        \n        print(f\"\\n=== å¤šé‡æ¯”è¼ƒè£œæ­£çµæœï¼ˆBonferroniæ³•ï¼‰ ===\")\n        print(f\"è£œæ­£å‰Î± = {self.significance_level}\")\n        print(f\"è£œæ­£å¾ŒÎ± = {alpha_bonf:.4f}\")\n        \n        significant_results = results_df[results_df['æœ‰æ„']]\n        if len(significant_results) > 0:\n            print(\"\\næœ‰æ„ãªå¤‰åŒ–:\")\n            for _, row in significant_results.iterrows():\n                direction = \"æ”¹å–„\" if row['å¤‰åŒ–'] > 0 else \"æ‚ªåŒ–\"\n                print(f\"ãƒ»{row['ç‰©è³ª']}: {row['å¤‰åŒ–']:+.1f}ãƒã‚¤ãƒ³ãƒˆ ({direction})\" + \n                      f\" p={row['på€¤_è£œæ­£']:.4f}\")\n        else:\n            print(\"\\næœ‰æ„ãªå¤‰åŒ–ãªã—\")\n        \n        print()\n        return results_df\n    \n    def calculate_composite_scores(self):\n        \"\"\"ç·åˆã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã¨å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š\"\"\"\n        print(\"=== ç·åˆã‚¹ã‚³ã‚¢åˆ†æ ===\")\n        \n        substances = list(self.correct_answers.keys())\n        \n        # å„å€‹äººã®ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—\n        before_scores = []\n        after_scores = []\n        \n        for idx in self.matched_df.index:\n            before_score = 0\n            after_score = 0\n            valid_items = 0\n            \n            for substance in substances:\n                before_col = f'{substance}_before_correct'\n                after_col = f'{substance}_after_correct'\n                \n                if (pd.notna(self.matched_df.loc[idx, before_col]) and \n                    pd.notna(self.matched_df.loc[idx, after_col])):\n                    before_score += int(self.matched_df.loc[idx, before_col])\n                    after_score += int(self.matched_df.loc[idx, after_col])\n                    valid_items += 1\n            \n            if valid_items >= 4:  # 4é …ç›®ä»¥ä¸Šæœ‰åŠ¹ãªå ´åˆã®ã¿\n                before_scores.append(before_score / valid_items * 100)  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆåŒ–\n                after_scores.append(after_score / valid_items * 100)\n        \n        before_scores = np.array(before_scores)\n        after_scores = np.array(after_scores)\n        \n        print(f\"ç·åˆã‚¹ã‚³ã‚¢åˆ†æå¯¾è±¡: {len(before_scores)}å\")\n        \n        # è¨˜è¿°çµ±è¨ˆ\n        print(f\"\\n=== è¨˜è¿°çµ±è¨ˆ ===\")\n        print(f\"æˆæ¥­å‰å¹³å‡: {before_scores.mean():.1f}% (SD: {before_scores.std():.1f})\")\n        print(f\"æˆæ¥­å¾Œå¹³å‡: {after_scores.mean():.1f}% (SD: {after_scores.std():.1f})\")\n        print(f\"å¹³å‡å¤‰åŒ–: {(after_scores - before_scores).mean():.1f}ãƒã‚¤ãƒ³ãƒˆ\")\n        \n        # å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š\n        t_stat, p_value = stats.ttest_rel(after_scores, before_scores)\n        \n        # åŠ¹æœé‡ï¼ˆCohen's dï¼‰\n        diff = after_scores - before_scores\n        cohens_d = diff.mean() / diff.std()\n        \n        print(f\"\\n=== å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š ===\")\n        print(f\"tçµ±è¨ˆé‡: {t_stat:.3f}\")\n        print(f\"på€¤: {p_value:.4f}\")\n        print(f\"åŠ¹æœé‡ (Cohen's d): {cohens_d:.3f}\")\n        \n        # åŠ¹æœé‡ã®è§£é‡ˆ\n        if abs(cohens_d) < 0.2:\n            effect_interpretation = \"å°ã•ã„\"\n        elif abs(cohens_d) < 0.5:\n            effect_interpretation = \"ä¸­ç¨‹åº¦\"\n        elif abs(cohens_d) < 0.8:\n            effect_interpretation = \"å¤§ãã„\"\n        else:\n            effect_interpretation = \"éå¸¸ã«å¤§ãã„\"\n        \n        print(f\"åŠ¹æœé‡è§£é‡ˆ: {effect_interpretation}\")\n        \n        # 95%ä¿¡é ¼åŒºé–“\n        n = len(diff)\n        se = diff.std() / np.sqrt(n)\n        ci_lower = diff.mean() - 1.96 * se\n        ci_upper = diff.mean() + 1.96 * se\n        \n        print(f\"å¹³å‡å¤‰åŒ–ã®95%ä¿¡é ¼åŒºé–“: [{ci_lower:.1f}, {ci_upper:.1f}]\")\n        \n        # æœ‰æ„æ€§åˆ¤å®š\n        is_significant = p_value < self.significance_level\n        print(f\"\\nçµæœ: {'æœ‰æ„' if is_significant else 'éæœ‰æ„'} (Î± = {self.significance_level})\")\n        \n        print()\n        \n        return {\n            'before_scores': before_scores,\n            'after_scores': after_scores,\n            't_statistic': t_stat,\n            'p_value': p_value,\n            'cohens_d': cohens_d,\n            'ci_lower': ci_lower,\n            'ci_upper': ci_upper,\n            'is_significant': is_significant\n        }\n    \n    def power_analysis(self, observed_effect_size=None):\n        \"\"\"ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¨æ¤œå‡ºåŠ›åˆ†æ\"\"\"\n        print(\"=== ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãƒ»æ¤œå‡ºåŠ›åˆ†æ ===\")\n        \n        current_n = len(self.matched_df)\n        \n        if observed_effect_size is None:\n            # ç·åˆã‚¹ã‚³ã‚¢ã‹ã‚‰åŠ¹æœé‡ã‚’å–å¾—\n            composite_results = self.calculate_composite_scores()\n            observed_effect_size = abs(composite_results['cohens_d'])\n        \n        # ç¾åœ¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã§ã®æ¤œå‡ºåŠ›\n        current_power = ttest_power(observed_effect_size, current_n, self.significance_level)\n        \n        # å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆæ¤œå‡ºåŠ›0.8ï¼‰\n        required_n_80 = pg.power_ttest(d=observed_effect_size, power=0.8, alpha=self.significance_level)\n        required_n_90 = pg.power_ttest(d=observed_effect_size, power=0.9, alpha=self.significance_level)\n        \n        print(f\"è¦³æ¸¬ã•ã‚ŒãŸåŠ¹æœé‡: {observed_effect_size:.3f}\")\n        print(f\"ç¾åœ¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {current_n}\")\n        print(f\"ç¾åœ¨ã®æ¤œå‡ºåŠ›: {current_power:.3f}\")\n        print(f\"æ¤œå‡ºåŠ›0.8ã«å¿…è¦ãªN: {required_n_80:.0f}\")\n        print(f\"æ¤œå‡ºåŠ›0.9ã«å¿…è¦ãªN: {required_n_90:.0f}\")\n        \n        # åŠ¹æœé‡åˆ¥å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º\n        print(f\"\\n=== åŠ¹æœé‡åˆ¥å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆæ¤œå‡ºåŠ›0.8ï¼‰ ===\")\n        for d in [0.2, 0.5, 0.8]:\n            n_needed = pg.power_ttest(d=d, power=0.8, alpha=self.significance_level)\n            interpretation = [\"å°\", \"ä¸­\", \"å¤§\"][int(d*5-1)]\n            print(f\"åŠ¹æœé‡ {d} ({interpretation}): N = {n_needed:.0f}\")\n        \n        print()\n        \n        return {\n            'current_n': current_n,\n            'observed_effect_size': observed_effect_size,\n            'current_power': current_power,\n            'required_n_80': required_n_80,\n            'required_n_90': required_n_90\n        }\n    \n    def q3_tea_analysis(self):\n        \"\"\"Q3ï¼ˆãŠèŒ¶ã®ç†è§£åº¦ï¼‰ã®è©³ç´°åˆ†æ\"\"\"\n        print(\"=== Q3 ãŠèŒ¶ã®ç†è§£åº¦åˆ†æ ===\")\n        \n        # Q3é …ç›®ã®ç¢ºèª\n        q3_cols_before = [col for col in self.before_df.columns if 'Q3_' in col]\n        q3_cols_after = [col for col in self.after_df.columns if 'Q3_' in col]\n        \n        print(f\"æˆæ¥­å‰Q3é …ç›®: {q3_cols_before}\")\n        print(f\"æˆæ¥­å¾ŒQ3é …ç›®: {q3_cols_after}\")\n        \n        if not q3_cols_before or not q3_cols_after:\n            print(\"Q3é …ç›®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n            return\n        \n        # é …ç›®å¯¾å¿œï¼ˆä»®å®šï¼‰\n        q3_mapping = []\n        for before_col in q3_cols_before:\n            for after_col in q3_cols_after:\n                if 'Dissolve' in before_col and 'Dissolve' in after_col:\n                    if ('Leaves' in before_col and 'Leaves' in after_col) or \\\n                       ('Components' in before_col and 'Components' in after_col):\n                        q3_mapping.append((before_col, after_col))\n        \n        if not q3_mapping:\n            print(\"Q3é …ç›®ã®å¯¾å¿œé–¢ä¿‚ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n            return\n        \n        print(f\"\\nQ3é …ç›®å¯¾å¿œé–¢ä¿‚:\")\n        results = []\n        \n        for before_col, after_col in q3_mapping:\n            print(f\"{before_col} â†” {after_col}\")\n            \n            # ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n            matched_before = self.before_df.set_index('Page_ID')\n            matched_after = self.after_df.set_index('Page_ID')\n            common_ids = matched_before.index.intersection(matched_after.index)\n            \n            before_data = matched_before.loc[common_ids, before_col]\n            after_data = matched_after.loc[common_ids, after_col]\n            \n            # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n            valid_mask = before_data.notna() & after_data.notna()\n            before_valid = before_data[valid_mask]\n            after_valid = after_data[valid_mask]\n            \n            if len(before_valid) == 0:\n                continue\n            \n            # McNemaræ¤œå®š\n            tt = ((before_valid == True) & (after_valid == True)).sum()\n            tf = ((before_valid == True) & (after_valid == False)).sum()\n            ft = ((before_valid == False) & (after_valid == True)).sum()\n            ff = ((before_valid == False) & (after_valid == False)).sum()\n            \n            contingency_table = np.array([[tt, tf], [ft, ff]])\n            \n            if tf + ft > 0:\n                try:\n                    result = mcnemar(contingency_table, exact=True)\n                    p_value = result.pvalue\n                    statistic = result.statistic\n                except:\n                    result = mcnemar(contingency_table, exact=False, correction=True)\n                    p_value = result.pvalue\n                    statistic = result.statistic\n            else:\n                p_value = 1.0\n                statistic = 0.0\n            \n            before_rate = before_valid.mean() * 100\n            after_rate = after_valid.mean() * 100\n            change = after_rate - before_rate\n            \n            results.append({\n                'é …ç›®': after_col.replace('Q3_', '').replace('_', ' '),\n                'N': len(before_valid),\n                'æˆæ¥­å‰æ­£ç­”ç‡': round(before_rate, 1),\n                'æˆæ¥­å¾Œæ­£ç­”ç‡': round(after_rate, 1),\n                'å¤‰åŒ–': round(change, 1),\n                'på€¤': round(p_value, 4)\n            })\n        \n        if results:\n            results_df = pd.DataFrame(results)\n            print(f\"\\nQ3é …ç›®åˆ†æçµæœ:\")\n            print(results_df.to_string(index=False))\n        \n        print()\n        return results\n    \n    def create_visualization(self, mcnemar_results, composite_results):\n        \"\"\"çµæœã®å¯è¦–åŒ–\"\"\"\n        print(\"=== çµæœå¯è¦–åŒ– ===\")\n        \n        # 1. McNemaræ¤œå®šçµæœã®å¯è¦–åŒ–\n        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n        \n        # æ­£ç­”ç‡å¤‰åŒ–ã®æ£’ã‚°ãƒ©ãƒ•\n        substances = mcnemar_results['ç‰©è³ª']\n        changes = mcnemar_results['å¤‰åŒ–']\n        colors = ['red' if x < 0 else 'blue' for x in changes]\n        \n        axes[0,0].bar(substances, changes, color=colors, alpha=0.7)\n        axes[0,0].set_title('Q1é …ç›® æ­£ç­”ç‡å¤‰åŒ–')\n        axes[0,0].set_ylabel('å¤‰åŒ–ï¼ˆãƒã‚¤ãƒ³ãƒˆï¼‰')\n        axes[0,0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n        axes[0,0].tick_params(axis='x', rotation=45)\n        \n        # æœ‰æ„æ€§ã®è¡¨ç¤º\n        for i, (substance, change, significant) in enumerate(zip(substances, changes, mcnemar_results['æœ‰æ„'])):\n            if significant:\n                axes[0,0].text(i, change + (1 if change >= 0 else -1), '*', \n                              ha='center', va='bottom' if change >= 0 else 'top', \n                              fontsize=16, color='red')\n        \n        # æˆæ¥­å‰å¾Œæ­£ç­”ç‡ã®æ¯”è¼ƒ\n        x = np.arange(len(substances))\n        width = 0.35\n        \n        axes[0,1].bar(x - width/2, mcnemar_results['æˆæ¥­å‰æ­£ç­”ç‡'], width, \n                     label='æˆæ¥­å‰', alpha=0.7)\n        axes[0,1].bar(x + width/2, mcnemar_results['æˆæ¥­å¾Œæ­£ç­”ç‡'], width, \n                     label='æˆæ¥­å¾Œ', alpha=0.7)\n        axes[0,1].set_title('æˆæ¥­å‰å¾Œæ­£ç­”ç‡æ¯”è¼ƒ')\n        axes[0,1].set_ylabel('æ­£ç­”ç‡ (%)')\n        axes[0,1].set_xticks(x)\n        axes[0,1].set_xticklabels(substances, rotation=45)\n        axes[0,1].legend()\n        \n        # ç·åˆã‚¹ã‚³ã‚¢ã®æ•£å¸ƒå›³\n        before_scores = composite_results['before_scores']\n        after_scores = composite_results['after_scores']\n        \n        axes[1,0].scatter(before_scores, after_scores, alpha=0.6)\n        min_score = min(before_scores.min(), after_scores.min())\n        max_score = max(before_scores.max(), after_scores.max())\n        axes[1,0].plot([min_score, max_score], [min_score, max_score], 'r--', alpha=0.5)\n        axes[1,0].set_xlabel('æˆæ¥­å‰ç·åˆã‚¹ã‚³ã‚¢ (%)')\n        axes[1,0].set_ylabel('æˆæ¥­å¾Œç·åˆã‚¹ã‚³ã‚¢ (%)')\n        axes[1,0].set_title('å€‹äººåˆ¥ç·åˆã‚¹ã‚³ã‚¢å¤‰åŒ–')\n        \n        # å¤‰åŒ–é‡ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n        changes_individual = after_scores - before_scores\n        axes[1,1].hist(changes_individual, bins=15, alpha=0.7, edgecolor='black')\n        axes[1,1].axvline(x=0, color='red', linestyle='--', alpha=0.7)\n        axes[1,1].axvline(x=changes_individual.mean(), color='blue', linestyle='-', \n                         label=f'å¹³å‡: {changes_individual.mean():.1f}')\n        axes[1,1].set_xlabel('ç·åˆã‚¹ã‚³ã‚¢å¤‰åŒ– (ãƒã‚¤ãƒ³ãƒˆ)')\n        axes[1,1].set_ylabel('äººæ•°')\n        axes[1,1].set_title('å€‹äººåˆ¥ã‚¹ã‚³ã‚¢å¤‰åŒ–åˆ†å¸ƒ')\n        axes[1,1].legend()\n        \n        plt.tight_layout()\n        \n        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n        output_dir = 'reports/2025-05-30/'\n        os.makedirs(output_dir, exist_ok=True)\n        plt.savefig(os.path.join(output_dir, 'phase2_statistical_results.png'), \n                   dpi=300, bbox_inches='tight')\n        print(f\"å›³è¡¨ä¿å­˜: {output_dir}phase2_statistical_results.png\")\n        \n        plt.show()\n    \n    def generate_phase2_summary(self, mcnemar_results, composite_results, power_results):\n        \"\"\"Phase 2 çµæœã‚µãƒãƒªãƒ¼\"\"\"\n        print(\"=\" * 60)\n        print(\"Phase 2 æ•™è‚²åŠ¹æœã®çµ±è¨ˆçš„æ¤œè¨¼ çµæœã‚µãƒãƒªãƒ¼\")\n        print(\"=\" * 60)\n        \n        print(f\"\\nğŸ“Š åˆ†ææ¦‚è¦:\")\n        print(f\"ãƒ»åˆ†æå¯¾è±¡: {len(self.matched_df)}åã®å‰å¾Œãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿\")\n        print(f\"ãƒ»æ¤œå®šé …ç›®: Q1æ°´æº¶æ¶²èªè­˜6é …ç›® + ç·åˆã‚¹ã‚³ã‚¢\")\n        print(f\"ãƒ»æœ‰æ„æ°´æº–: Î± = {self.significance_level}\")\n        print(f\"ãƒ»å¤šé‡æ¯”è¼ƒè£œæ­£: Bonferroniæ³•\")\n        \n        print(f\"\\nğŸ” McNemaræ¤œå®šçµæœ:\")\n        significant_items = mcnemar_results[mcnemar_results['æœ‰æ„']]\n        if len(significant_items) > 0:\n            print(f\"ãƒ»æœ‰æ„ãªå¤‰åŒ–: {len(significant_items)}/{len(mcnemar_results)}é …ç›®\")\n            for _, row in significant_items.iterrows():\n                direction = \"æ”¹å–„\" if row['å¤‰åŒ–'] > 0 else \"æ‚ªåŒ–\"\n                print(f\"  - {row['ç‰©è³ª']}: {row['å¤‰åŒ–']:+.1f}ãƒã‚¤ãƒ³ãƒˆ ({direction}, p={row['på€¤_è£œæ­£']:.4f})\")\n        else:\n            print(\"ãƒ»æœ‰æ„ãªå¤‰åŒ–: ãªã—\")\n        \n        # æ”¹å–„å‚¾å‘ã®é …ç›®\n        improved_items = mcnemar_results[mcnemar_results['å¤‰åŒ–'] > 0]\n        print(f\"ãƒ»æ”¹å–„å‚¾å‘: {len(improved_items)}/{len(mcnemar_results)}é …ç›®\")\n        if len(improved_items) > 0:\n            for _, row in improved_items.iterrows():\n                sig = \" *\" if row['æœ‰æ„'] else \"\"\n                print(f\"  - {row['ç‰©è³ª']}: +{row['å¤‰åŒ–']:.1f}ãƒã‚¤ãƒ³ãƒˆ{sig}\")\n        \n        print(f\"\\nğŸ“ˆ ç·åˆã‚¹ã‚³ã‚¢åˆ†æ:\")\n        print(f\"ãƒ»å¹³å‡å¤‰åŒ–: {(composite_results['after_scores'] - composite_results['before_scores']).mean():.1f}ãƒã‚¤ãƒ³ãƒˆ\")\n        print(f\"ãƒ»åŠ¹æœé‡ (Cohen's d): {composite_results['cohens_d']:.3f}\")\n        print(f\"ãƒ»çµ±è¨ˆçš„æœ‰æ„æ€§: {'æœ‰æ„' if composite_results['is_significant'] else 'éæœ‰æ„'} (p={composite_results['p_value']:.4f})\")\n        print(f\"ãƒ»95%ä¿¡é ¼åŒºé–“: [{composite_results['ci_lower']:.1f}, {composite_results['ci_upper']:.1f}]\")\n        \n        print(f\"\\nâš¡ æ¤œå‡ºåŠ›åˆ†æ:\")\n        print(f\"ãƒ»ç¾åœ¨ã®æ¤œå‡ºåŠ›: {power_results['current_power']:.3f}\")\n        print(f\"ãƒ»æ¤œå‡ºåŠ›0.8ã«å¿…è¦ãªN: {power_results['required_n_80']:.0f}å\")\n        \n        adequacy = \"ååˆ†\" if power_results['current_power'] >= 0.8 else \"ä¸è¶³\"\n        print(f\"ãƒ»ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {adequacy}\")\n        \n        print(f\"\\nâœ… Phase 2 å®Œäº†åˆ¤å®š:\")\n        \n        # ä¸»è¦ä»®èª¬ã®æ¤œè¨¼\n        hypothesis_results = []\n        \n        # ä»®èª¬1: æˆæ¥­å¾Œã®æ°´æº¶æ¶²ç†è§£åº¦ã¯æœ‰æ„ã«å‘ä¸Šã™ã‚‹\n        overall_improvement = composite_results['is_significant'] and composite_results['cohens_d'] > 0\n        hypothesis_results.append((\"ä»®èª¬1ï¼ˆå…¨ä½“çš„æ”¹å–„ï¼‰\", \"æ”¯æŒ\" if overall_improvement else \"æ£„å´\"))\n        \n        # ä»®èª¬2ï¼ˆåŠ¹æœé‡ï¼‰: d > 0.5ã®æœŸå¾…\n        large_effect = abs(composite_results['cohens_d']) > 0.5\n        hypothesis_results.append((\"ä»®èª¬2ï¼ˆå¤§ããªåŠ¹æœï¼‰\", \"æ”¯æŒ\" if large_effect else \"æ£„å´\"))\n        \n        # å€‹åˆ¥é …ç›®ã§ã®æ”¹å–„\n        any_significant = len(significant_items) > 0\n        hypothesis_results.append((\"å€‹åˆ¥é …ç›®æ”¹å–„\", \"ç¢ºèª\" if any_significant else \"æœªç¢ºèª\"))\n        \n        for hypothesis, result in hypothesis_results:\n            status = \"ğŸŸ¢\" if result in [\"æ”¯æŒ\", \"ç¢ºèª\"] else \"ğŸŸ¡\"\n            print(f\"{status} {hypothesis}: {result}\")\n        \n        print(f\"\\nğŸ¯ ä¸»è¦ãªçŸ¥è¦‹:\")\n        \n        # ç‰¹ã«æ”¹å–„ãŒè¦‹ã‚‰ã‚ŒãŸé ˜åŸŸ\n        non_solution_items = mcnemar_results[mcnemar_results['ç‰©è³ª'].isin(['Muddywater', 'Ink'])]\n        if len(non_solution_items) > 0:\n            avg_non_solution_change = non_solution_items['å¤‰åŒ–'].mean()\n            print(f\"ãƒ»éæ°´æº¶æ¶²ã®ç†è§£ãŒå¤§å¹…æ”¹å–„ (å¹³å‡+{avg_non_solution_change:.1f}ãƒã‚¤ãƒ³ãƒˆ)\")\n        \n        solution_items = mcnemar_results[mcnemar_results['ç‰©è³ª'].isin(['MisoSoup', 'SoySauce'])]\n        if len(solution_items) > 0:\n            avg_solution_change = solution_items['å¤‰åŒ–'].mean()\n            if avg_solution_change < 0:\n                print(f\"ãƒ»æ—¥å¸¸çš„æ°´æº¶æ¶²ã§èª²é¡Œã‚ã‚Š (å¹³å‡{avg_solution_change:.1f}ãƒã‚¤ãƒ³ãƒˆ)\")\n        \n        print(f\"\\nğŸ”„ æ¬¡ã‚¹ãƒ†ãƒƒãƒ—:\")\n        if any_significant or overall_improvement:\n            print(\"ğŸŸ¢ Phase 3 (é›†å›£é–“å·®ç•°åˆ†æ) ã«é€²è¡Œ\")\n        else:\n            print(\"ğŸŸ¡ åŠ¹æœãŒé™å®šçš„ - Phase 3ã§è©³ç´°åˆ†æã‚’å®Ÿæ–½\")\n        \n        print(\"=\" * 60)\n        \n        return {\n            'significant_items': len(significant_items),\n            'improved_items': len(improved_items),\n            'overall_significant': composite_results['is_significant'],\n            'effect_size': composite_results['cohens_d'],\n            'power_adequate': power_results['current_power'] >= 0.8\n        }\n    \n    def run_full_analysis(self):\n        \"\"\"Phase 2 ãƒ•ãƒ«åˆ†æã®å®Ÿè¡Œ\"\"\"\n        print(\"Phase 2: æ•™è‚²åŠ¹æœã®çµ±è¨ˆçš„æ¤œè¨¼ å®Ÿè¡Œé–‹å§‹\")\n        print(\"=\" * 60)\n        \n        # 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™\n        self.load_and_prepare_data()\n        \n        # 2. McNemaræ¤œå®š\n        mcnemar_results = self.mcnemar_test_analysis()\n        \n        # 3. ç·åˆã‚¹ã‚³ã‚¢åˆ†æ\n        composite_results = self.calculate_composite_scores()\n        \n        # 4. æ¤œå‡ºåŠ›åˆ†æ\n        power_results = self.power_analysis(observed_effect_size=abs(composite_results['cohens_d']))\n        \n        # 5. Q3åˆ†æï¼ˆã‚ã‚Œã°ï¼‰\n        q3_results = self.q3_tea_analysis()\n        \n        # 6. å¯è¦–åŒ–\n        self.create_visualization(mcnemar_results, composite_results)\n        \n        # 7. çµæœã‚µãƒãƒªãƒ¼\n        summary = self.generate_phase2_summary(mcnemar_results, composite_results, power_results)\n        \n        return {\n            'mcnemar_results': mcnemar_results,\n            'composite_results': composite_results,\n            'power_results': power_results,\n            'q3_results': q3_results,\n            'summary': summary\n        }\n\ndef main():\n    \"\"\"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°\"\"\"\n    analyzer = Phase2StatisticalTesting()\n    results = analyzer.run_full_analysis()\n    \n    print(\"\\nğŸ‰ Phase 2 çµ±è¨ˆçš„æ¤œè¨¼å®Œäº†!\")\n    \n    if results['summary']['overall_significant'] or results['summary']['significant_items'] > 0:\n        print(\"âœ… æ•™è‚²åŠ¹æœã‚’çµ±è¨ˆçš„ã«ç¢ºèª\")\n        print(\"æ¬¡ã‚¹ãƒ†ãƒƒãƒ—: Phase 3 (é›†å›£é–“å·®ç•°åˆ†æ) ã®å®Ÿè¡Œ\")\n    else:\n        print(\"â„¹ï¸ å…¨ä½“çš„ãªåŠ¹æœã¯é™å®šçš„\")\n        print(\"æ¬¡ã‚¹ãƒ†ãƒƒãƒ—: Phase 3ã§ã®è©³ç´°åˆ†æã§è¦å› ã‚’æ¢ç´¢\")\n    \n    return results\n\nif __name__ == \"__main__\":\n    results = main()