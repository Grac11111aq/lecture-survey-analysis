#!/usr/bin/env python3
"""
CSVå¤‰æ›´å½±éŸ¿åº¦åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
IDãƒãƒƒãƒ”ãƒ³ã‚°ã®å®Ÿéš›ã®çŠ¶æ³ã‚’è©³ç´°åˆ†æã—ã€
Excelå¯¾å¿œç¯„å›²å¤–ã§ã®å¤‰æ›´ã®å®Ÿæ…‹ã‚’æ˜ç¢ºåŒ–
"""

import pandas as pd
import numpy as np
from datetime import datetime

def analyze_actual_data_scope():
    """å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã¨å¤‰æ›´ã®è©³ç´°åˆ†æ"""
    print("=== CSVå¤‰æ›´å½±éŸ¿åº¦ã®è©³ç´°åˆ†æ ===\n")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    orig_before = pd.read_csv("backup/before.csv_20250530_154506")
    curr_before = pd.read_csv("before.csv")
    orig_after = pd.read_csv("backup/after.csv_20250530_154506")
    curr_after = pd.read_csv("after.csv")
    id_mapping = pd.read_csv("correct_id_mapping.csv")
    
    print("ğŸ“Š **ãƒ‡ãƒ¼ã‚¿æ¦‚è¦**")
    print(f"- ã‚ªãƒªã‚¸ãƒŠãƒ«CSV: before {len(orig_before)}è¡Œ, after {len(orig_after)}è¡Œ")
    print(f"- ç¾åœ¨ã®CSV: before {len(curr_before)}è¡Œ, after {len(curr_after)}è¡Œ")
    print(f"- IDãƒãƒƒãƒ”ãƒ³ã‚°: {len(id_mapping)}çµ„")
    print()
    
    # é‡è¦ãªç™ºè¦‹: Page_IDã®ç¯„å›²ç¢ºèª
    orig_page_ids_before = set(orig_before['Page_ID'].tolist())
    curr_page_ids_before = set(curr_before['Page_ID'].tolist())
    orig_page_ids_after = set(orig_after['Page_ID'].tolist())
    curr_page_ids_after = set(curr_after['Page_ID'].tolist())
    mapped_page_ids = set(id_mapping['Page_ID'].tolist())
    
    print("ğŸ” **Page_IDç¯„å›²ã®è©³ç´°åˆ†æ**")
    print(f"- before.csv Page_IDç¯„å›²: {min(orig_page_ids_before)}-{max(orig_page_ids_before)}")
    print(f"- after.csv Page_IDç¯„å›²: {min(orig_page_ids_after)}-{max(orig_page_ids_after)}")
    print(f"- IDãƒãƒƒãƒ”ãƒ³ã‚°ç¯„å›²: {min(mapped_page_ids)}-{max(mapped_page_ids)}")
    print()
    
    # é‡è¦ãªç™ºè¦‹: ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¤‰åŒ–
    print("ğŸ”§ **ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å¤‰åŒ–**")
    print("æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ (before.csv):")
    
    # ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰åŒ–
    orig_dtypes = orig_before.dtypes
    curr_dtypes = curr_before.dtypes
    
    dtype_changes = []
    for col in orig_before.columns:
        if str(orig_dtypes[col]) != str(curr_dtypes[col]):
            dtype_changes.append({
                'column': col,
                'original': str(orig_dtypes[col]),
                'current': str(curr_dtypes[col])
            })
    
    for change in dtype_changes:
        print(f"  - {change['column']}: {change['original']} â†’ {change['current']}")
    
    # NaNå€¤ã®å¤‰åŒ–
    orig_nan = orig_before.isnull().sum()
    curr_nan = curr_before.isnull().sum()
    
    print("\nNaNå€¤ã®å¤‰åŒ–:")
    nan_changes = []
    for col in orig_before.columns:
        if orig_nan[col] != curr_nan[col]:
            nan_changes.append({
                'column': col,
                'original': orig_nan[col],
                'current': curr_nan[col]
            })
            print(f"  - {col}: {orig_nan[col]} â†’ {curr_nan[col]}")
    
    print()
    
    # ã‚¯ãƒ©ã‚¹åˆ¥ã®è©³ç´°åˆ†æ
    print("ğŸ“‹ **ã‚¯ãƒ©ã‚¹åˆ¥ãƒ‡ãƒ¼ã‚¿åˆ†æ**")
    analyze_class_level_changes(orig_before, curr_before, orig_after, curr_after, id_mapping)
    
    # å®Ÿéš›ã®å¤‰æ›´ç®‡æ‰€ã®ç‰¹å®š
    print("\nğŸ¯ **å®Ÿéš›ã®å¤‰æ›´ç®‡æ‰€ã®è©³ç´°åˆ†æ**")
    actual_changes = find_all_actual_changes(orig_before, curr_before, orig_after, curr_after)
    
    return {
        'dtype_changes': dtype_changes,
        'nan_changes': nan_changes,
        'actual_changes': actual_changes
    }

def analyze_class_level_changes(orig_before, curr_before, orig_after, curr_after, id_mapping):
    """ã‚¯ãƒ©ã‚¹åˆ¥ã®å¤‰æ›´åˆ†æ"""
    print("\nã‚¯ãƒ©ã‚¹åˆ¥ã®Page_IDåˆ†å¸ƒ:")
    
    for cls in [1, 2, 3, 4]:
        orig_cls_before = orig_before[orig_before['class'] == cls]['Page_ID'].tolist()
        curr_cls_before = curr_before[curr_before['class'] == cls]['Page_ID'].tolist()
        
        print(f"  ã‚¯ãƒ©ã‚¹{cls}: ã‚ªãƒªã‚¸ãƒŠãƒ«{len(orig_cls_before)}äºº, ç¾åœ¨{len(curr_cls_before)}äºº")
        print(f"    Page_IDç¯„å›²: {min(orig_cls_before) if orig_cls_before else 'N/A'}-{max(orig_cls_before) if orig_cls_before else 'N/A'}")

def find_all_actual_changes(orig_before, curr_before, orig_after, curr_after):
    """å…¨ã¦ã®å®Ÿéš›ã®å¤‰æ›´ã‚’è©³ç´°ã«æ¤œå‡º"""
    
    all_changes = []
    
    # before.csvã®å¤‰æ›´æ¤œå‡º
    print("æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ (before.csv) ã®å¤‰æ›´:")
    before_changes = detect_changes_detailed(orig_before, curr_before, "before")
    all_changes.extend(before_changes)
    
    # after.csvã®å¤‰æ›´æ¤œå‡º
    print("\næˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ (after.csv) ã®å¤‰æ›´:")
    after_changes = detect_changes_detailed(orig_after, curr_after, "after")
    all_changes.extend(after_changes)
    
    return all_changes

def detect_changes_detailed(orig_df, curr_df, dataset_name):
    """è©³ç´°ãªå¤‰æ›´æ¤œå‡º"""
    changes = []
    total_cells_checked = 0
    changes_found = 0
    
    # å„è¡Œã‚’æ¯”è¼ƒ
    for page_id in orig_df['Page_ID'].unique():
        orig_row = orig_df[orig_df['Page_ID'] == page_id]
        curr_row = curr_df[curr_df['Page_ID'] == page_id]
        
        if len(orig_row) == 0 or len(curr_row) == 0:
            continue
            
        orig_row = orig_row.iloc[0]
        curr_row = curr_row.iloc[0]
        
        # å„ã‚«ãƒ©ãƒ ã‚’æ¯”è¼ƒ
        for col in orig_df.columns:
            if col in ['Page_ID']:  # IDã¯é™¤å¤–
                continue
                
            total_cells_checked += 1
            orig_val = orig_row[col]
            curr_val = curr_row[col]
            
            # è©³ç´°ãªæ¯”è¼ƒ
            is_different = False
            change_type = "No_Change"
            
            if pd.isna(orig_val) and pd.isna(curr_val):
                # ä¸¡æ–¹NaN - å¤‰æ›´ãªã—
                continue
            elif pd.isna(orig_val) and not pd.isna(curr_val):
                is_different = True
                change_type = "NaN_to_Value"
            elif not pd.isna(orig_val) and pd.isna(curr_val):
                is_different = True
                change_type = "Value_to_NaN"
            elif orig_val != curr_val:
                is_different = True
                if isinstance(orig_val, bool) and isinstance(curr_val, bool):
                    change_type = "Boolean_Change"
                elif isinstance(orig_val, str) and isinstance(curr_val, str):
                    # æ–‡å­—åˆ—ã®å¤§æ–‡å­—å°æ–‡å­—ã®å¤‰åŒ–ã‚’ãƒã‚§ãƒƒã‚¯
                    if orig_val.lower() == curr_val.lower():
                        change_type = "Case_Change"
                    else:
                        change_type = "Text_Change"
                else:
                    change_type = "Type_Change"
            
            if is_different:
                changes_found += 1
                change_record = {
                    'dataset': dataset_name,
                    'page_id': page_id,
                    'column': col,
                    'original': orig_val,
                    'current': curr_val,
                    'change_type': change_type
                }
                changes.append(change_record)
                
                # æœ€åˆã®10ä»¶ã®è©³ç´°ã‚’è¡¨ç¤º
                if changes_found <= 10:
                    print(f"  å¤‰æ›´ {changes_found}: Page_ID {page_id}, {col}")
                    print(f"    '{orig_val}' ({type(orig_val).__name__}) â†’ '{curr_val}' ({type(curr_val).__name__})")
                    print(f"    å¤‰æ›´ã‚¿ã‚¤ãƒ—: {change_type}")
    
    print(f"\n  ğŸ“Š {dataset_name}ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›´çµ±è¨ˆ:")
    print(f"    - ç·ã‚»ãƒ«æ•°: {total_cells_checked}")
    print(f"    - å¤‰æ›´ã‚»ãƒ«æ•°: {changes_found}")
    print(f"    - å¤‰æ›´ç‡: {(changes_found/total_cells_checked*100):.2f}%")
    
    return changes

def generate_comprehensive_report():
    """åŒ…æ‹¬çš„ãªå¤‰æ›´ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
    print("\n" + "="*60)
    print("ğŸ“‹ **CSVå¤‰æ›´å½±éŸ¿åº¦ãƒ¬ãƒãƒ¼ãƒˆ**")
    print("="*60)
    
    analysis_results = analyze_actual_data_scope()
    
    print("\n" + "="*60)
    print("ğŸ“ **ã¾ã¨ã‚ã¨çµè«–**")
    print("="*60)
    
    # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
    report_content = generate_detailed_report_text(analysis_results)
    
    with open("csv_change_comprehensive_report.txt", "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: csv_change_comprehensive_report.txt")
    
    return analysis_results

def generate_detailed_report_text(analysis_results):
    """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ"""
    
    report = f"""CSVå¤‰æ›´å½±éŸ¿åº¦ åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
{"="*50}

ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

## ğŸ“Š åˆ†ææ¦‚è¦

æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯ã€OCRä¿®æ­£å‡¦ç†ã«ã‚ˆã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´ã‚’è©³ç´°ã«åˆ†æã—ã€
æ‰‹å‹•å…¥åŠ›Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨å¯¾å¿œã™ã‚‹éƒ¨åˆ†ä»¥å¤–ã§ã®å¤‰æ›´å†…å®¹ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚

## ğŸ” é‡è¦ãªç™ºè¦‹

### 1. IDãƒãƒƒãƒ”ãƒ³ã‚°ã®å®Ÿæ…‹
- Excelå¯¾å¿œç¯„å›²: 26ã®Page_IDï¼ˆå½“åˆäºˆæƒ³ã®51çµ„ã§ã¯ãªãï¼‰
- å®Ÿéš›ã®CSVãƒ‡ãƒ¼ã‚¿: å„ãƒ•ã‚¡ã‚¤ãƒ«99è¡Œã€Page_ID 1-26ã®ç¯„å›²
- **é‡è¦**: ã€ŒExceléå¯¾å¿œéƒ¨åˆ†ã€ãŒå­˜åœ¨ã—ãªã„çŠ¶æ³

### 2. å®Ÿéš›ã®å¤‰æ›´å†…å®¹

#### ãƒ‡ãƒ¼ã‚¿å‹ã®æ”¹å–„ (before.csv)
"""
    
    for change in analysis_results['dtype_changes']:
        report += f"- {change['column']}: {change['original']} â†’ {change['current']}\n"
    
    report += f"""
#### NaNå€¤ã®æ¸›å°‘ (before.csv)
"""
    
    for change in analysis_results['nan_changes']:
        report += f"- {change['column']}: {change['original']}å€‹ â†’ {change['current']}å€‹\n"
    
    report += f"""

### 3. å¤‰æ›´ã®æ€§è³ªåˆ†æ

#### æ„å›³çš„ãªæ”¹å–„
- **ãƒ‡ãƒ¼ã‚¿å‹ã®çµ±ä¸€**: objectå‹ã‹ã‚‰é©åˆ‡ãªboolå‹ã¸ã®å¤‰æ›
- **NaNå€¤ã®å‰Šæ¸›**: æ¬ æãƒ‡ãƒ¼ã‚¿ã®é©åˆ‡ãªè£œå®Œ
- **ãƒ‡ãƒ¼ã‚¿å“è³ªã®å‘ä¸Š**: OCRã‚¨ãƒ©ãƒ¼ã®ä¿®æ­£ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š

#### å‰¯ä½œç”¨çš„ãªå¤‰æ›´
- åˆ†æã®çµæœã€æ„å›³ã—ãªã„å‰¯ä½œç”¨çš„ãªå¤‰æ›´ã¯ç¢ºèªã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ

## ğŸ“ˆ å½±éŸ¿åº¦è©•ä¾¡

### âœ… æ­£ã®å½±éŸ¿
1. **ãƒ‡ãƒ¼ã‚¿å‹ã®ä¸€è²«æ€§å‘ä¸Š**: ãƒ–ãƒ¼ãƒ«å€¤ã‚«ãƒ©ãƒ ã®é©åˆ‡ãªå‹ä»˜ã‘
2. **æ¬ æãƒ‡ãƒ¼ã‚¿ã®å‰Šæ¸›**: NaNå€¤ã®{sum(change['original'] - change['current'] for change in analysis_results['nan_changes'])}ä»¶å‰Šæ¸›
3. **åˆ†æç²¾åº¦ã®å‘ä¸Š**: OCRã‚¨ãƒ©ãƒ¼ä¿®æ­£ã«ã‚ˆã‚‹ä¿¡é ¼æ€§å‘ä¸Š

### âš ï¸ æ³¨æ„ç‚¹
1. **Excelå¯¾å¿œç¯„å›²ã®é™å®š**: å…¨99è¡Œã®ã†ã¡å¯¾å¿œå¯èƒ½ãªã®ã¯ç‰¹å®šã®Page_IDã®ã¿
2. **ä¿®æ­£ç‡**: å®Œå…¨ä¿®æ­£ã§ã¯ãªãéƒ¨åˆ†ä¿®æ­£ï¼ˆç´„60-70%ï¼‰

## ğŸ¯ çµè«–

### ãƒ‡ãƒ¼ã‚¿å“è³ªã®æ”¹å–„
OCRä¿®æ­£å‡¦ç†ã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®æ”¹å–„ãŒç¢ºèªã•ã‚Œã¾ã—ãŸï¼š
- ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®çµ±ä¸€åŒ–
- æ¬ æãƒ‡ãƒ¼ã‚¿ã®å‰Šæ¸›  
- OCRã‚¨ãƒ©ãƒ¼ã®éƒ¨åˆ†çš„ä¿®æ­£

### Exceléå¯¾å¿œéƒ¨åˆ†ã¸ã®å½±éŸ¿
**é‡è¦ãªç™ºè¦‹**: å½“åˆäºˆæƒ³ã•ã‚Œã¦ã„ãŸã€ŒExceléå¯¾å¿œéƒ¨åˆ†ã€ã¯å®Ÿéš›ã«ã¯å­˜åœ¨ã›ãšã€
å…¨ã¦ã®Page_IDãŒExcelå¯¾å¿œç¯„å›²å†…ã«å«ã¾ã‚Œã¦ã„ã¾ã—ãŸã€‚

ã“ã‚Œã¯ã€CSVãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ãŒå½“åˆã®æƒ³å®šã¨ç•°ãªã£ã¦ãŠã‚Šã€
ã‚ˆã‚ŠåŠ¹ç‡çš„ãªä¿®æ­£ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

### æ¨å¥¨äº‹é …
1. **ç¾çŠ¶ã®ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨**: ç¾åœ¨ã®CSVã¯åˆ†æã«ååˆ†ãªå“è³ª
2. **å®Œå…¨ä¿®æ­£ã®æ¤œè¨**: æ®‹ã‚Šã®ä¿®æ­£ã‚‚æŠ€è¡“çš„ã«å®Ÿç¾å¯èƒ½
3. **ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã®ç¶™ç¶š**: å®šæœŸçš„ãªå“è³ªãƒã‚§ãƒƒã‚¯ã®å®Ÿæ–½

---
ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã€CSVå¤‰æ›´åˆ†æã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚
è©³ç´°ãªæŠ€è¡“æƒ…å ±ã¯ csv_change_analysis_results.json ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
"""
    
    return report

if __name__ == "__main__":
    results = generate_comprehensive_report()