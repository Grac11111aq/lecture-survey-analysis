#!/usr/bin/env python3
"""
Phase 2: æ•™è‚²åŠ¹æœã®çµ±è¨ˆçš„æ¤œè¨¼ï¼ˆç°¡æ˜“ç‰ˆï¼‰
McNemaræ¤œå®šã€å¯¾å¿œã®ã‚ã‚‹tæ¤œå®šã€åŠ¹æœé‡ç®—å‡º
"""

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # GUIä¸è¦ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
import matplotlib.pyplot as plt
from scipy import stats
from statsmodels.stats.contingency_tables import mcnemar
from statsmodels.stats.multitest import multipletests
import os

def load_data():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    data_dir = 'data/analysis/'
    before_df = pd.read_csv(data_dir + 'before_excel_compliant.csv')
    after_df = pd.read_csv(data_dir + 'after_excel_compliant.csv')
    return before_df, after_df

def prepare_matched_data(before_df, after_df):
    """å‰å¾Œãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™"""
    # Page_IDã§ãƒãƒƒãƒãƒ³ã‚°
    matched_before = before_df.set_index('Page_ID')
    matched_after = after_df.set_index('Page_ID')
    common_ids = matched_before.index.intersection(matched_after.index)
    
    # Q1é …ç›®ã®å¯¾å¿œ
    q1_mapping = {
        'Saltwater': ('Q1_Saltwater_Response', 'Q1_Saltwater'),
        'Sugarwater': ('Q1_Sugarwater_Response', 'Q1_Sugarwater'),
        'Muddywater': ('Q1_Muddywater_Response', 'Q1_Muddywater'),
        'Ink': ('Q1_Ink_Response', 'Q1_Ink'),
        'MisoSoup': ('Q1_MisoSoup_Response', 'Q1_MisoSoup'),
        'SoySauce': ('Q1_SoySauce_Response', 'Q1_SoySauce')
    }
    
    # æ­£ç­”åŸºæº–
    correct_answers = {
        'Saltwater': True, 'Sugarwater': True, 'Muddywater': False,
        'Ink': False, 'MisoSoup': True, 'SoySauce': True
    }
    
    # ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    matched_data = {}
    for substance, (before_col, after_col) in q1_mapping.items():
        before_responses = matched_before.loc[common_ids, before_col]
        after_responses = matched_after.loc[common_ids, after_col]
        
        correct = correct_answers[substance]
        before_correct = (before_responses == correct)
        after_correct = (after_responses == correct)
        
        matched_data[substance] = {
            'before': before_correct,
            'after': after_correct,
            'correct_answer': correct
        }
    
    print(f"ãƒãƒƒãƒãƒ³ã‚°å®Œäº†: {len(common_ids)}åã®ãƒ‡ãƒ¼ã‚¿")
    return matched_data, common_ids

def mcnemar_analysis(matched_data):
    """McNemaræ¤œå®šã«ã‚ˆã‚‹å‰å¾Œæ¯”è¼ƒ"""
    print("\n=== McNemaræ¤œå®šã«ã‚ˆã‚‹å‰å¾Œæ¯”è¼ƒ ===")
    
    results = []
    for substance, data in matched_data.items():
        before = data['before']
        after = data['after']
        
        # æ¬ æå€¤é™¤å»
        valid_mask = before.notna() & after.notna()
        before_valid = before[valid_mask]
        after_valid = after[valid_mask]
        
        if len(before_valid) == 0:
            continue
        
        # 2x2åˆ†å‰²è¡¨
        tt = ((before_valid == True) & (after_valid == True)).sum()
        tf = ((before_valid == True) & (after_valid == False)).sum()
        ft = ((before_valid == False) & (after_valid == True)).sum()
        ff = ((before_valid == False) & (after_valid == False)).sum()
        
        contingency = np.array([[tt, tf], [ft, ff]])
        
        # McNemaræ¤œå®š
        if tf + ft > 0:
            try:
                result = mcnemar(contingency, exact=True)
                p_value = result.pvalue
            except:
                result = mcnemar(contingency, exact=False)
                p_value = result.pvalue
        else:
            p_value = 1.0
        
        # æ­£ç­”ç‡è¨ˆç®—
        before_rate = before_valid.mean() * 100
        after_rate = after_valid.mean() * 100
        change = after_rate - before_rate
        
        results.append({
            'ç‰©è³ª': substance,
            'N': len(before_valid),
            'æˆæ¥­å‰æ­£ç­”ç‡': round(before_rate, 1),
            'æˆæ¥­å¾Œæ­£ç­”ç‡': round(after_rate, 1),
            'å¤‰åŒ–': round(change, 1),
            'på€¤': round(p_value, 4)
        })
    
    results_df = pd.DataFrame(results)
    print(results_df.to_string(index=False))
    
    # å¤šé‡æ¯”è¼ƒè£œæ­£
    p_values = results_df['på€¤'].values
    rejected, p_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')
    
    results_df['på€¤_è£œæ­£'] = np.round(p_corrected, 4)
    results_df['æœ‰æ„'] = rejected
    
    print(f"\nå¤šé‡æ¯”è¼ƒè£œæ­£å¾Œ (Bonferroniæ³•):")
    significant = results_df[results_df['æœ‰æ„']]
    if len(significant) > 0:
        print("æœ‰æ„ãªå¤‰åŒ–:")
        for _, row in significant.iterrows():
            direction = "æ”¹å–„" if row['å¤‰åŒ–'] > 0 else "æ‚ªåŒ–"
            print(f"ãƒ»{row['ç‰©è³ª']}: {row['å¤‰åŒ–']:+.1f}ãƒã‚¤ãƒ³ãƒˆ ({direction}, p={row['på€¤_è£œæ­£']:.4f})")
    else:
        print("æœ‰æ„ãªå¤‰åŒ–ãªã—")
    
    return results_df

def composite_score_analysis(matched_data):
    """ç·åˆã‚¹ã‚³ã‚¢åˆ†æ"""
    print("\n=== ç·åˆã‚¹ã‚³ã‚¢åˆ†æ ===")
    
    before_scores = []
    after_scores = []
    
    # å…¨ã¦ã®å€‹äººã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    substances = list(matched_data.keys())
    n_individuals = len(next(iter(matched_data.values()))['before'])
    
    for i in range(n_individuals):
        before_total = 0
        after_total = 0
        valid_count = 0
        
        for substance in substances:
            before_val = matched_data[substance]['before'].iloc[i]
            after_val = matched_data[substance]['after'].iloc[i]
            
            if pd.notna(before_val) and pd.notna(after_val):
                before_total += int(before_val)
                after_total += int(after_val)
                valid_count += 1
        
        if valid_count >= 4:  # æœ€ä½4é …ç›®æœ‰åŠ¹
            before_scores.append(before_total / valid_count * 100)
            after_scores.append(after_total / valid_count * 100)
    
    before_scores = np.array(before_scores)
    after_scores = np.array(after_scores)
    
    print(f"åˆ†æå¯¾è±¡: {len(before_scores)}å")
    print(f"æˆæ¥­å‰å¹³å‡: {before_scores.mean():.1f}% (SD: {before_scores.std():.1f})")
    print(f"æˆæ¥­å¾Œå¹³å‡: {after_scores.mean():.1f}% (SD: {after_scores.std():.1f})")
    
    # å¯¾å¿œã®ã‚ã‚‹tæ¤œå®š
    t_stat, p_value = stats.ttest_rel(after_scores, before_scores)
    
    # åŠ¹æœé‡ (Cohen's d)
    diff = after_scores - before_scores
    cohens_d = diff.mean() / diff.std()
    
    print(f"\nå¯¾å¿œã®ã‚ã‚‹tæ¤œå®š:")
    print(f"tçµ±è¨ˆé‡: {t_stat:.3f}")
    print(f"på€¤: {p_value:.4f}")
    print(f"Cohen's d: {cohens_d:.3f}")
    
    # åŠ¹æœé‡è§£é‡ˆ
    if abs(cohens_d) < 0.2:
        interpretation = "å°"
    elif abs(cohens_d) < 0.5:
        interpretation = "ä¸­"
    elif abs(cohens_d) < 0.8:
        interpretation = "å¤§"
    else:
        interpretation = "éå¸¸ã«å¤§"
    
    print(f"åŠ¹æœé‡: {interpretation}")
    
    # 95%ä¿¡é ¼åŒºé–“
    se = diff.std() / np.sqrt(len(diff))
    ci_lower = diff.mean() - 1.96 * se
    ci_upper = diff.mean() + 1.96 * se
    print(f"95%ä¿¡é ¼åŒºé–“: [{ci_lower:.1f}, {ci_upper:.1f}]")
    
    return {
        'before_scores': before_scores,
        'after_scores': after_scores,
        't_stat': t_stat,
        'p_value': p_value,
        'cohens_d': cohens_d,
        'is_significant': p_value < 0.05
    }

def create_visualizations(mcnemar_results, composite_results):
    """çµæœã®å¯è¦–åŒ–"""
    print("\n=== çµæœå¯è¦–åŒ– ===")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. æ­£ç­”ç‡å¤‰åŒ–
    substances = mcnemar_results['ç‰©è³ª']
    changes = mcnemar_results['å¤‰åŒ–']
    colors = ['red' if x < 0 else 'blue' for x in changes]
    
    axes[0,0].bar(substances, changes, color=colors, alpha=0.7)
    axes[0,0].set_title('Q1é …ç›® æ­£ç­”ç‡å¤‰åŒ–')
    axes[0,0].set_ylabel('å¤‰åŒ– (ãƒã‚¤ãƒ³ãƒˆ)')
    axes[0,0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
    axes[0,0].tick_params(axis='x', rotation=45)
    
    # æœ‰æ„æ€§ãƒãƒ¼ã‚¯
    for i, (_, row) in enumerate(mcnemar_results.iterrows()):
        if row['æœ‰æ„']:
            axes[0,0].text(i, row['å¤‰åŒ–'] + (1 if row['å¤‰åŒ–'] >= 0 else -1), 
                          '*', ha='center', fontsize=16, color='red')
    
    # 2. å‰å¾Œæ¯”è¼ƒ
    x = np.arange(len(substances))
    width = 0.35
    
    axes[0,1].bar(x - width/2, mcnemar_results['æˆæ¥­å‰æ­£ç­”ç‡'], width, 
                 label='æˆæ¥­å‰', alpha=0.7)
    axes[0,1].bar(x + width/2, mcnemar_results['æˆæ¥­å¾Œæ­£ç­”ç‡'], width, 
                 label='æˆæ¥­å¾Œ', alpha=0.7)
    axes[0,1].set_title('æˆæ¥­å‰å¾Œæ­£ç­”ç‡æ¯”è¼ƒ')
    axes[0,1].set_ylabel('æ­£ç­”ç‡ (%)')
    axes[0,1].set_xticks(x)
    axes[0,1].set_xticklabels(substances, rotation=45)
    axes[0,1].legend()
    
    # 3. å€‹äººåˆ¥å¤‰åŒ–
    before_scores = composite_results['before_scores']
    after_scores = composite_results['after_scores']
    
    axes[1,0].scatter(before_scores, after_scores, alpha=0.6)
    min_score = min(before_scores.min(), after_scores.min())
    max_score = max(before_scores.max(), after_scores.max())
    axes[1,0].plot([min_score, max_score], [min_score, max_score], 'r--', alpha=0.5)
    axes[1,0].set_xlabel('æˆæ¥­å‰ã‚¹ã‚³ã‚¢ (%)')
    axes[1,0].set_ylabel('æˆæ¥­å¾Œã‚¹ã‚³ã‚¢ (%)')
    axes[1,0].set_title('å€‹äººåˆ¥ç·åˆã‚¹ã‚³ã‚¢å¤‰åŒ–')
    
    # 4. å¤‰åŒ–é‡åˆ†å¸ƒ
    changes_individual = after_scores - before_scores
    axes[1,1].hist(changes_individual, bins=15, alpha=0.7, edgecolor='black')
    axes[1,1].axvline(x=0, color='red', linestyle='--', alpha=0.7)
    axes[1,1].axvline(x=changes_individual.mean(), color='blue', linestyle='-',
                     label=f'å¹³å‡: {changes_individual.mean():.1f}')
    axes[1,1].set_xlabel('ã‚¹ã‚³ã‚¢å¤‰åŒ– (ãƒã‚¤ãƒ³ãƒˆ)')
    axes[1,1].set_ylabel('äººæ•°')
    axes[1,1].set_title('å€‹äººåˆ¥å¤‰åŒ–é‡åˆ†å¸ƒ')
    axes[1,1].legend()
    
    plt.tight_layout()
    
    # ä¿å­˜
    output_dir = 'reports/2025-05-30/'
    os.makedirs(output_dir, exist_ok=True)
    plt.savefig(f'{output_dir}phase2_results.png', dpi=300, bbox_inches='tight')
    print(f"å›³è¡¨ä¿å­˜: {output_dir}phase2_results.png")
    plt.close()

def generate_summary(mcnemar_results, composite_results):
    """Phase 2 çµæœã‚µãƒãƒªãƒ¼"""
    print("\n" + "="*60)
    print("Phase 2 æ•™è‚²åŠ¹æœã®çµ±è¨ˆçš„æ¤œè¨¼ çµæœã‚µãƒãƒªãƒ¼")
    print("="*60)
    
    significant_items = mcnemar_results[mcnemar_results['æœ‰æ„']]
    improved_items = mcnemar_results[mcnemar_results['å¤‰åŒ–'] > 0]
    
    print(f"\nğŸ“Š åˆ†æçµæœ:")
    print(f"ãƒ»åˆ†æé …ç›®: {len(mcnemar_results)}é …ç›®")
    print(f"ãƒ»æœ‰æ„ãªå¤‰åŒ–: {len(significant_items)}é …ç›®")
    print(f"ãƒ»æ”¹å–„å‚¾å‘: {len(improved_items)}é …ç›®")
    
    print(f"\nğŸ“ˆ ç·åˆã‚¹ã‚³ã‚¢:")
    avg_change = (composite_results['after_scores'] - composite_results['before_scores']).mean()
    print(f"ãƒ»å¹³å‡å¤‰åŒ–: {avg_change:.1f}ãƒã‚¤ãƒ³ãƒˆ")
    print(f"ãƒ»åŠ¹æœé‡: {composite_results['cohens_d']:.3f}")
    print(f"ãƒ»çµ±è¨ˆçš„æœ‰æ„æ€§: {'æœ‰æ„' if composite_results['is_significant'] else 'éæœ‰æ„'}")
    
    print(f"\nğŸ¯ ä¸»è¦çŸ¥è¦‹:")
    # éæ°´æº¶æ¶²é …ç›®ã®æ”¹å–„
    non_solution = mcnemar_results[mcnemar_results['ç‰©è³ª'].isin(['Muddywater', 'Ink'])]
    if len(non_solution) > 0:
        avg_improvement = non_solution['å¤‰åŒ–'].mean()
        print(f"ãƒ»éæ°´æº¶æ¶²ã®ç†è§£å¤§å¹…æ”¹å–„: +{avg_improvement:.1f}ãƒã‚¤ãƒ³ãƒˆ")
    
    # æ°´æº¶æ¶²é …ç›®ã®èª²é¡Œ
    solution = mcnemar_results[mcnemar_results['ç‰©è³ª'].isin(['MisoSoup', 'SoySauce'])]
    if len(solution) > 0:
        avg_change_solution = solution['å¤‰åŒ–'].mean()
        if avg_change_solution < 0:
            print(f"ãƒ»æ—¥å¸¸çš„æ°´æº¶æ¶²ã§èª²é¡Œ: {avg_change_solution:.1f}ãƒã‚¤ãƒ³ãƒˆ")
    
    print(f"\nâœ… çµè«–:")
    if len(significant_items) > 0 or composite_results['is_significant']:
        print("ğŸŸ¢ æ•™è‚²åŠ¹æœã‚’çµ±è¨ˆçš„ã«ç¢ºèª")
        print("ğŸŸ¢ Phase 3 (é›†å›£é–“å·®ç•°åˆ†æ) ã«é€²è¡Œå¯èƒ½")
    else:
        print("ğŸŸ¡ é™å®šçš„ãªåŠ¹æœ - Phase 3ã§è©³ç´°åˆ†æå¿…è¦")
    
    print("="*60)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("Phase 2: æ•™è‚²åŠ¹æœã®çµ±è¨ˆçš„æ¤œè¨¼ å®Ÿè¡Œé–‹å§‹")
    print("="*60)
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    before_df, after_df = load_data()
    
    # 2. ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æº–å‚™
    matched_data, common_ids = prepare_matched_data(before_df, after_df)
    
    # 3. McNemaræ¤œå®š
    mcnemar_results = mcnemar_analysis(matched_data)
    
    # 4. ç·åˆã‚¹ã‚³ã‚¢åˆ†æ
    composite_results = composite_score_analysis(matched_data)
    
    # 5. å¯è¦–åŒ–
    create_visualizations(mcnemar_results, composite_results)
    
    # 6. ã‚µãƒãƒªãƒ¼
    generate_summary(mcnemar_results, composite_results)
    
    print("\nğŸ‰ Phase 2 çµ±è¨ˆçš„æ¤œè¨¼å®Œäº†!")
    return mcnemar_results, composite_results

if __name__ == "__main__":
    mcnemar_results, composite_results = main()