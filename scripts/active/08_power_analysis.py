#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çµ±è¨ˆçš„æ¤œå‡ºåŠ›åˆ†æã¨ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—
===================================

å®Ÿæ–½ã—ãŸåˆ†æã®çµ±è¨ˆçš„å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ã€å°†æ¥ã®ç ”ç©¶è¨­è¨ˆã¸ã®æè¨€ã‚’æä¾›ã€‚

æ©Ÿèƒ½:
- å„çµ±è¨ˆæ¤œå®šã®äº‹å¾Œæ¤œå‡ºåŠ›è¨ˆç®—
- åŠ¹æœé‡åˆ¥ã®å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—
- Bootstrapæ³•ã«ã‚ˆã‚‹ä¿¡é ¼åŒºé–“æ¨å®š
- çµ±è¨ˆçš„æœ‰æ„æ€§ã®å¦¥å½“æ€§è©•ä¾¡
- å°†æ¥ç ”ç©¶ã¸ã®è¨­è¨ˆæè¨€

å¯¾è±¡åˆ†æ:
- Ï‡Â²æ¤œå®šã®æ¤œå‡ºåŠ›
- Mann-Whitney Uæ¤œå®šã®æ¤œå‡ºåŠ›
- ç›¸é–¢åˆ†æã®æ¤œå‡ºåŠ›
- æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®çµ±è¨ˆçš„ä¿¡é ¼æ€§

Author: Claude Code Analysis (Power Analysis Implementation)
Date: 2025-05-31
"""

import os
import sys
import json
import warnings
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import chi2_contingency, mannwhitneyu, pearsonr
import statsmodels.stats.power as smp
import statsmodels.stats.contingency_tables as smt

# Bootstrapåˆ†æç”¨
from sklearn.utils import resample

# è­¦å‘ŠæŠ‘åˆ¶
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

class PowerAnalysisEvaluator:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.data_dir = self.project_root / "data" / "analysis"
        self.output_dir = self.project_root / "outputs" / "current" / "05_advanced_analysis"
        self.figures_dir = self.project_root / "outputs" / "figures" / "current" / "05_advanced_analysis"
        
        # æ—¢å­˜çµæœã®èª­ã¿è¾¼ã¿ãƒ‘ã‚¹
        self.sem_results_path = self.output_dir / "structural_equation_modeling_results.json"
        self.ml_results_path = self.output_dir / "machine_learning_prediction_results.json"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.figures_dir.mkdir(parents=True, exist_ok=True)
        
        self.results = {}
        
    def load_data_and_results(self):
        """ãƒ‡ãƒ¼ã‚¿ã¨æ—¢å­˜åˆ†æçµæœã®èª­ã¿è¾¼ã¿"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã¨æ—¢å­˜çµæœèª­ã¿è¾¼ã¿ä¸­...")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        before_path = self.data_dir / "before_excel_compliant.csv"
        after_path = self.data_dir / "after_excel_compliant.csv"
        
        if not before_path.exists() or not after_path.exists():
            raise FileNotFoundError("å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        self.before_data = pd.read_csv(before_path, encoding='utf-8')
        self.after_data = pd.read_csv(after_path, encoding='utf-8')
        
        print(f"âœ“ æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿: {len(self.before_data)} ä»¶")
        print(f"âœ“ æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿: {len(self.after_data)} ä»¶")
        
        # æ—¢å­˜åˆ†æçµæœèª­ã¿è¾¼ã¿
        self._load_existing_results()
        
    def _load_existing_results(self):
        """æ—¢å­˜åˆ†æçµæœèª­ã¿è¾¼ã¿"""
        self.existing_results = {}
        
        # SEMçµæœ
        if self.sem_results_path.exists():
            with open(self.sem_results_path, 'r', encoding='utf-8') as f:
                self.existing_results['sem'] = json.load(f)
            print("âœ“ SEMåˆ†æçµæœèª­ã¿è¾¼ã¿å®Œäº†")
        
        # MLçµæœ
        if self.ml_results_path.exists():
            with open(self.ml_results_path, 'r', encoding='utf-8') as f:
                self.existing_results['ml'] = json.load(f)
            print("âœ“ MLåˆ†æçµæœèª­ã¿è¾¼ã¿å®Œäº†")
    
    def calculate_effect_sizes(self):
        """åŠ¹æœé‡è¨ˆç®—"""
        print("\nğŸ“ åŠ¹æœé‡è¨ˆç®—ä¸­...")
        
        effect_sizes = {}
        
        # Q1ç·åˆã‚¹ã‚³ã‚¢åŠ¹æœé‡è¨ˆç®—
        effect_sizes['q1_composite'] = self._calculate_q1_effect_size()
        
        # Q3ç·åˆã‚¹ã‚³ã‚¢åŠ¹æœé‡è¨ˆç®—
        effect_sizes['q3_composite'] = self._calculate_q3_effect_size()
        
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®åŠ¹æœé‡ï¼ˆCramÃ©r's Vï¼‰
        effect_sizes['categorical'] = self._calculate_categorical_effect_sizes()
        
        self.results['effect_sizes'] = effect_sizes
        
        print("âœ“ åŠ¹æœé‡è¨ˆç®—å®Œäº†")
        
    def _calculate_q1_effect_size(self):
        """Q1ç·åˆã‚¹ã‚³ã‚¢åŠ¹æœé‡è¨ˆç®—"""
        # Q1ã‚¹ã‚³ã‚¢è¨ˆç®—
        q1_before_cols = ['Q1_Saltwater_Response', 'Q1_Sugarwater_Response', 'Q1_Muddywater_Response', 
                         'Q1_Ink_Response', 'Q1_MisoSoup_Response', 'Q1_SoySauce_Response']
        q1_after_cols = ['Q1_Saltwater', 'Q1_Sugarwater', 'Q1_Muddywater',
                        'Q1_Ink', 'Q1_MisoSoup', 'Q1_SoySauce']
        
        before_scores = self.before_data[q1_before_cols].sum(axis=1)
        after_scores = self.after_data[q1_after_cols].sum(axis=1)
        
        # Cohen's dè¨ˆç®—
        mean_diff = after_scores.mean() - before_scores.mean()
        pooled_std = np.sqrt(((len(before_scores) - 1) * before_scores.var() + 
                             (len(after_scores) - 1) * after_scores.var()) / 
                            (len(before_scores) + len(after_scores) - 2))
        
        cohens_d = mean_diff / pooled_std
        
        # Mann-Whitney Uæ¤œå®š
        u_stat, u_p = mannwhitneyu(before_scores, after_scores, alternative='two-sided')
        
        # åŠ¹æœé‡r
        n_total = len(before_scores) + len(after_scores)
        z_score = stats.norm.ppf(u_p/2)  # è¿‘ä¼¼
        effect_r = abs(z_score) / np.sqrt(n_total)
        
        return {
            'before_mean': before_scores.mean(),
            'after_mean': after_scores.mean(),
            'before_std': before_scores.std(),
            'after_std': after_scores.std(),
            'mean_difference': mean_diff,
            'cohens_d': cohens_d,
            'mann_whitney_u': u_stat,
            'mann_whitney_p': u_p,
            'effect_size_r': effect_r,
            'sample_size_before': len(before_scores),
            'sample_size_after': len(after_scores)
        }
    
    def _calculate_q3_effect_size(self):
        """Q3ç·åˆã‚¹ã‚³ã‚¢åŠ¹æœé‡è¨ˆç®—"""
        # Q3ã‚¹ã‚³ã‚¢è¨ˆç®—
        q3_before_cols = ['Q3_TeaLeavesDissolve', 'Q3_TeaComponentsDissolve']
        q3_after_cols = ['Q3_TeaLeaves_DissolveInWater', 'Q3_TeaComponents_DissolveInWater']
        
        before_scores = self.before_data[q3_before_cols].sum(axis=1)
        after_scores = self.after_data[q3_after_cols].sum(axis=1)
        
        # Cohen's dè¨ˆç®—
        mean_diff = after_scores.mean() - before_scores.mean()
        pooled_std = np.sqrt(((len(before_scores) - 1) * before_scores.var() + 
                             (len(after_scores) - 1) * after_scores.var()) / 
                            (len(before_scores) + len(after_scores) - 2))
        
        cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0
        
        # Mann-Whitney Uæ¤œå®š
        u_stat, u_p = mannwhitneyu(before_scores, after_scores, alternative='two-sided')
        
        return {
            'before_mean': before_scores.mean(),
            'after_mean': after_scores.mean(),
            'before_std': before_scores.std(),
            'after_std': after_scores.std(),
            'mean_difference': mean_diff,
            'cohens_d': cohens_d,
            'mann_whitney_u': u_stat,
            'mann_whitney_p': u_p,
            'sample_size_before': len(before_scores),
            'sample_size_after': len(after_scores)
        }
    
    def _calculate_categorical_effect_sizes(self):
        """ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°åŠ¹æœé‡è¨ˆç®—"""
        categorical_effects = {}
        
        # Q1å„é …ç›®ã®CramÃ©r's V
        q1_items = [
            ('Saltwater', 'Q1_Saltwater_Response', 'Q1_Saltwater'),
            ('Sugarwater', 'Q1_Sugarwater_Response', 'Q1_Sugarwater'),
            ('Muddywater', 'Q1_Muddywater_Response', 'Q1_Muddywater'),
            ('Ink', 'Q1_Ink_Response', 'Q1_Ink'),
            ('MisoSoup', 'Q1_MisoSoup_Response', 'Q1_MisoSoup'),
            ('SoySauce', 'Q1_SoySauce_Response', 'Q1_SoySauce')
        ]
        
        for item_name, before_col, after_col in q1_items:
            if before_col in self.before_data.columns and after_col in self.after_data.columns:
                # ã‚¯ãƒ­ã‚¹é›†è¨ˆè¡¨ä½œæˆ
                before_counts = self.before_data[before_col].value_counts()
                after_counts = self.after_data[after_col].value_counts()
                
                # å…±é€šã®ã‚«ãƒ†ã‚´ãƒªã§é›†è¨ˆè¡¨ä½œæˆ
                all_categories = sorted(set(before_counts.index) | set(after_counts.index))
                
                contingency_table = []
                for cat in all_categories:
                    before_count = before_counts.get(cat, 0)
                    after_count = after_counts.get(cat, 0)
                    contingency_table.append([before_count, after_count])
                
                contingency_table = np.array(contingency_table).T
                
                # Ï‡Â²æ¤œå®šã¨CramÃ©r's V
                if contingency_table.sum() > 0:
                    try:
                        chi2, p_value, dof, expected = chi2_contingency(contingency_table)
                        n = contingency_table.sum()
                        cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))
                        
                        categorical_effects[item_name] = {
                            'chi2': chi2,
                            'p_value': p_value,
                            'degrees_of_freedom': dof,
                            'cramers_v': cramers_v,
                            'sample_size': n,
                            'contingency_table': contingency_table.tolist()
                        }
                    except ValueError as e:
                        categorical_effects[item_name] = {'error': str(e)}
        
        return categorical_effects
    
    def calculate_post_hoc_power(self):
        """äº‹å¾Œæ¤œå‡ºåŠ›è¨ˆç®—"""
        print("\nâš¡ äº‹å¾Œæ¤œå‡ºåŠ›è¨ˆç®—ä¸­...")
        
        power_results = {}
        
        # tæ¤œå®šã®æ¤œå‡ºåŠ›ï¼ˆQ1, Q3ç·åˆã‚¹ã‚³ã‚¢ï¼‰
        power_results['t_tests'] = self._calculate_t_test_power()
        
        # Ï‡Â²æ¤œå®šã®æ¤œå‡ºåŠ›
        power_results['chi2_tests'] = self._calculate_chi2_power()
        
        # ç›¸é–¢åˆ†æã®æ¤œå‡ºåŠ›
        power_results['correlation_tests'] = self._calculate_correlation_power()
        
        self.results['power_analysis'] = power_results
        
        print("âœ“ äº‹å¾Œæ¤œå‡ºåŠ›è¨ˆç®—å®Œäº†")
    
    def _calculate_t_test_power(self):
        """tæ¤œå®šæ¤œå‡ºåŠ›è¨ˆç®—"""
        t_test_power = {}
        
        # Q1ç·åˆã‚¹ã‚³ã‚¢
        if 'q1_composite' in self.results['effect_sizes']:
            q1_effect = self.results['effect_sizes']['q1_composite']
            
            # ç‹¬ç«‹tæ¤œå®šã®æ¤œå‡ºåŠ›
            power_q1 = smp.ttest_power(
                effect_size=abs(q1_effect['cohens_d']),
                nobs=q1_effect['sample_size_before'],
                alpha=0.05,
                alternative='two-sided'
            )
            
            t_test_power['Q1_composite'] = {
                'effect_size': q1_effect['cohens_d'],
                'power': power_q1,
                'sample_size_before': q1_effect['sample_size_before'],
                'sample_size_after': q1_effect['sample_size_after'],
                'interpretation': self._interpret_power(power_q1)
            }
        
        # Q3ç·åˆã‚¹ã‚³ã‚¢
        if 'q3_composite' in self.results['effect_sizes']:
            q3_effect = self.results['effect_sizes']['q3_composite']
            
            power_q3 = smp.ttest_power(
                effect_size=abs(q3_effect['cohens_d']),
                nobs=q3_effect['sample_size_before'],
                alpha=0.05,
                alternative='two-sided'
            )
            
            t_test_power['Q3_composite'] = {
                'effect_size': q3_effect['cohens_d'],
                'power': power_q3,
                'sample_size_before': q3_effect['sample_size_before'],
                'sample_size_after': q3_effect['sample_size_after'],
                'interpretation': self._interpret_power(power_q3)
            }
        
        return t_test_power
    
    def _calculate_chi2_power(self):
        """Ï‡Â²æ¤œå®šæ¤œå‡ºåŠ›è¨ˆç®—"""
        chi2_power = {}
        
        if 'categorical' in self.results['effect_sizes']:
            for item_name, effect_data in self.results['effect_sizes']['categorical'].items():
                if 'error' not in effect_data:
                    # Ï‡Â²æ¤œå®šã®æ¤œå‡ºåŠ›è¨ˆç®—ï¼ˆè¿‘ä¼¼ï¼‰
                    cramers_v = effect_data['cramers_v']
                    n = effect_data['sample_size']
                    df = effect_data['degrees_of_freedom']
                    
                    # åŠ¹æœé‡ã‚’wï¼ˆCohenã®wï¼‰ã«å¤‰æ›
                    w = cramers_v * np.sqrt(df)
                    
                    # æ¤œå‡ºåŠ›è¨ˆç®—
                    try:
                        power = smp.GofChisquarePower().solve_power(
                            effect_size=w,
                            nobs=n,
                            alpha=0.05,
                            power=None
                        )
                        
                        chi2_power[item_name] = {
                            'cramers_v': cramers_v,
                            'cohens_w': w,
                            'power': power,
                            'sample_size': n,
                            'p_value': effect_data['p_value'],
                            'interpretation': self._interpret_power(power)
                        }
                    except Exception as e:
                        chi2_power[item_name] = {'error': f'æ¤œå‡ºåŠ›è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}'}
        
        return chi2_power
    
    def _calculate_correlation_power(self):
        """ç›¸é–¢åˆ†ææ¤œå‡ºåŠ›è¨ˆç®—"""
        correlation_power = {}
        
        # æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã§ã®ç›¸é–¢åˆ†æ
        after_data = self.after_data.copy()
        
        # Q1ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        q1_cols = ['Q1_Saltwater', 'Q1_Sugarwater', 'Q1_Muddywater',
                   'Q1_Ink', 'Q1_MisoSoup', 'Q1_SoySauce']
        after_data['Q1_total'] = after_data[q1_cols].sum(axis=1)
        
        # ç›¸é–¢åˆ†æå¯¾è±¡
        correlation_pairs = [
            ('Q1_total', 'Q4_ExperimentInterestRating'),
            ('Q1_total', 'Q6_DissolvingUnderstandingRating'),
            ('Q4_ExperimentInterestRating', 'Q5_NewLearningsRating'),
            ('Q5_NewLearningsRating', 'Q6_DissolvingUnderstandingRating')
        ]
        
        for var1, var2 in correlation_pairs:
            if var1 in after_data.columns and var2 in after_data.columns:
                # æ¬ æå€¤é™¤å»
                data_pair = after_data[[var1, var2]].dropna()
                
                if len(data_pair) > 5:  # æœ€å°ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                    r, p_value = pearsonr(data_pair[var1], data_pair[var2])
                    
                    # ç›¸é–¢ã®æ¤œå‡ºåŠ›è¨ˆç®—
                    try:
                        power = smp.ttest_power(
                            effect_size=abs(r),  # ç›¸é–¢ä¿‚æ•°ã‚’åŠ¹æœé‡ã¨ã—ã¦ä½¿ç”¨
                            nobs=len(data_pair),
                            alpha=0.05,
                            alternative='two-sided'
                        )
                        
                        correlation_power[f"{var1}_vs_{var2}"] = {
                            'correlation': r,
                            'p_value': p_value,
                            'power': power,
                            'sample_size': len(data_pair),
                            'interpretation': self._interpret_power(power)
                        }
                    except Exception as e:
                        correlation_power[f"{var1}_vs_{var2}"] = {'error': f'æ¤œå‡ºåŠ›è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}'}
        
        return correlation_power
    
    def _interpret_power(self, power):
        """æ¤œå‡ºåŠ›è§£é‡ˆ"""
        if power >= 0.8:
            return "ååˆ†ãªæ¤œå‡ºåŠ›"
        elif power >= 0.6:
            return "ä¸­ç¨‹åº¦ã®æ¤œå‡ºåŠ›"
        else:
            return "æ¤œå‡ºåŠ›ä¸è¶³"
    
    def calculate_required_sample_sizes(self):
        """å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—"""
        print("\nğŸ“Š å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—ä¸­...")
        
        sample_size_recommendations = {}
        
        # ç•°ãªã‚‹åŠ¹æœé‡ã§ã®å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
        effect_sizes = [0.2, 0.5, 0.8]  # å°ãƒ»ä¸­ãƒ»å¤§åŠ¹æœ
        desired_power = 0.8
        alpha = 0.05
        
        for effect_size in effect_sizes:
            # tæ¤œå®š
            try:
                n_t_test = smp.TTestPower().solve_power(
                    effect_size=effect_size,
                    power=desired_power,
                    alpha=alpha,
                    alternative='two-sided'
                )
            except:
                n_t_test = None
            
            # Ï‡Â²æ¤œå®šï¼ˆè‡ªç”±åº¦1ã¨ã—ã¦è¿‘ä¼¼ï¼‰
            try:
                n_chi2_test = smp.GofChisquarePower().solve_power(
                    effect_size=effect_size,
                    power=desired_power,
                    alpha=alpha,
                    n_bins=2
                )
            except:
                n_chi2_test = None
            
            # ç›¸é–¢åˆ†æ
            try:
                n_correlation = smp.TTestPower().solve_power(
                    effect_size=effect_size,
                    power=desired_power,
                    alpha=alpha,
                    alternative='two-sided'
                )
            except:
                n_correlation = None
            
            sample_size_recommendations[f"effect_size_{effect_size}"] = {
                'effect_size': effect_size,
                'effect_interpretation': self._interpret_effect_size(effect_size),
                't_test_n_per_group': n_t_test,
                'chi2_test_n_total': n_chi2_test,
                'correlation_n_total': n_correlation,
                'power': desired_power,
                'alpha': alpha
            }
        
        self.results['sample_size_recommendations'] = sample_size_recommendations
        
        print("âœ“ å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—å®Œäº†")
    
    def _interpret_effect_size(self, effect_size):
        """åŠ¹æœé‡è§£é‡ˆ"""
        if effect_size >= 0.8:
            return "å¤§åŠ¹æœ"
        elif effect_size >= 0.5:
            return "ä¸­åŠ¹æœ"
        elif effect_size >= 0.2:
            return "å°åŠ¹æœ"
        else:
            return "åŠ¹æœãªã—/æ¥µå°"
    
    def bootstrap_confidence_intervals(self):
        """Bootstrapæ³•ã«ã‚ˆã‚‹ä¿¡é ¼åŒºé–“æ¨å®š"""
        print("\nğŸ”„ Bootstrapä¿¡é ¼åŒºé–“æ¨å®šä¸­...")
        
        bootstrap_results = {}
        
        # Q1ç·åˆã‚¹ã‚³ã‚¢ã®Bootstrap
        bootstrap_results['q1_composite'] = self._bootstrap_q1_difference()
        
        # Q3ç·åˆã‚¹ã‚³ã‚¢ã®Bootstrap
        bootstrap_results['q3_composite'] = self._bootstrap_q3_difference()
        
        self.results['bootstrap_analysis'] = bootstrap_results
        
        print("âœ“ Bootstrapåˆ†æå®Œäº†")
    
    def _bootstrap_q1_difference(self, n_bootstrap=1000):
        """Q1ã‚¹ã‚³ã‚¢å·®ã®Bootstrapä¿¡é ¼åŒºé–“"""
        # Q1ã‚¹ã‚³ã‚¢è¨ˆç®—
        q1_before_cols = ['Q1_Saltwater_Response', 'Q1_Sugarwater_Response', 'Q1_Muddywater_Response', 
                         'Q1_Ink_Response', 'Q1_MisoSoup_Response', 'Q1_SoySauce_Response']
        q1_after_cols = ['Q1_Saltwater', 'Q1_Sugarwater', 'Q1_Muddywater',
                        'Q1_Ink', 'Q1_MisoSoup', 'Q1_SoySauce']
        
        before_scores = self.before_data[q1_before_cols].sum(axis=1).values
        after_scores = self.after_data[q1_after_cols].sum(axis=1).values
        
        # Bootstrapæ¨™æœ¬æŠ½å‡º
        bootstrap_diffs = []
        for _ in range(n_bootstrap):
            before_sample = resample(before_scores, n_samples=len(before_scores))
            after_sample = resample(after_scores, n_samples=len(after_scores))
            diff = after_sample.mean() - before_sample.mean()
            bootstrap_diffs.append(diff)
        
        bootstrap_diffs = np.array(bootstrap_diffs)
        
        # ä¿¡é ¼åŒºé–“è¨ˆç®—
        ci_lower = np.percentile(bootstrap_diffs, 2.5)
        ci_upper = np.percentile(bootstrap_diffs, 97.5)
        
        return {
            'observed_difference': after_scores.mean() - before_scores.mean(),
            'bootstrap_mean': bootstrap_diffs.mean(),
            'bootstrap_std': bootstrap_diffs.std(),
            'ci_95_lower': ci_lower,
            'ci_95_upper': ci_upper,
            'n_bootstrap': n_bootstrap,
            'significant': not (ci_lower <= 0 <= ci_upper)  # 0ã‚’å«ã¾ãªã‘ã‚Œã°æœ‰æ„
        }
    
    def _bootstrap_q3_difference(self, n_bootstrap=1000):
        """Q3ã‚¹ã‚³ã‚¢å·®ã®Bootstrapä¿¡é ¼åŒºé–“"""
        # Q3ã‚¹ã‚³ã‚¢è¨ˆç®—
        q3_before_cols = ['Q3_TeaLeavesDissolve', 'Q3_TeaComponentsDissolve']
        q3_after_cols = ['Q3_TeaLeaves_DissolveInWater', 'Q3_TeaComponents_DissolveInWater']
        
        before_scores = self.before_data[q3_before_cols].sum(axis=1).values
        after_scores = self.after_data[q3_after_cols].sum(axis=1).values
        
        # Bootstrapæ¨™æœ¬æŠ½å‡º
        bootstrap_diffs = []
        for _ in range(n_bootstrap):
            before_sample = resample(before_scores, n_samples=len(before_scores))
            after_sample = resample(after_scores, n_samples=len(after_scores))
            diff = after_sample.mean() - before_sample.mean()
            bootstrap_diffs.append(diff)
        
        bootstrap_diffs = np.array(bootstrap_diffs)
        
        # ä¿¡é ¼åŒºé–“è¨ˆç®—
        ci_lower = np.percentile(bootstrap_diffs, 2.5)
        ci_upper = np.percentile(bootstrap_diffs, 97.5)
        
        return {
            'observed_difference': after_scores.mean() - before_scores.mean(),
            'bootstrap_mean': bootstrap_diffs.mean(),
            'bootstrap_std': bootstrap_diffs.std(),
            'ci_95_lower': ci_lower,
            'ci_95_upper': ci_upper,
            'n_bootstrap': n_bootstrap,
            'significant': not (ci_lower <= 0 <= ci_upper)
        }
    
    def create_visualizations(self):
        """å¯è¦–åŒ–ä½œæˆ"""
        print("\nğŸ“Š å¯è¦–åŒ–ä½œæˆä¸­...")
        
        # 1. æ¤œå‡ºåŠ›åˆ†æçµæœ
        self._create_power_analysis_plot()
        
        # 2. åŠ¹æœé‡å¯è¦–åŒ–
        self._create_effect_size_plot()
        
        # 3. ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºæ¨å¥¨
        self._create_sample_size_recommendation_plot()
        
        # 4. Bootstrapä¿¡é ¼åŒºé–“
        self._create_bootstrap_plot()
        
    def _create_power_analysis_plot(self):
        """æ¤œå‡ºåŠ›åˆ†æãƒ—ãƒ­ãƒƒãƒˆ"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # tæ¤œå®šæ¤œå‡ºåŠ›
        if 'power_analysis' in self.results and 't_tests' in self.results['power_analysis']:
            t_tests = self.results['power_analysis']['t_tests']
            
            test_names = list(t_tests.keys())
            powers = [t_tests[name]['power'] for name in test_names]
            effect_sizes = [abs(t_tests[name]['effect_size']) for name in test_names]
            
            axes[0,0].bar(test_names, powers, color='skyblue', alpha=0.7)
            axes[0,0].axhline(y=0.8, color='red', linestyle='--', label='æ¨å¥¨æ¤œå‡ºåŠ›(0.8)')
            axes[0,0].set_title('tæ¤œå®šã®æ¤œå‡ºåŠ›')
            axes[0,0].set_ylabel('æ¤œå‡ºåŠ›')
            axes[0,0].legend()
            axes[0,0].set_ylim(0, 1)
            
            # åŠ¹æœé‡ã‚‚è¡¨ç¤º
            for i, (power, es) in enumerate(zip(powers, effect_sizes)):
                axes[0,0].text(i, power + 0.02, f'ES={es:.3f}', ha='center', fontsize=8)
        
        # Ï‡Â²æ¤œå®šæ¤œå‡ºåŠ›
        if 'chi2_tests' in self.results['power_analysis']:
            chi2_tests = self.results['power_analysis']['chi2_tests']
            
            valid_tests = {k: v for k, v in chi2_tests.items() if 'error' not in v}
            if valid_tests:
                test_names = list(valid_tests.keys())
                powers = [valid_tests[name]['power'] for name in test_names]
                
                axes[0,1].bar(test_names, powers, color='lightcoral', alpha=0.7)
                axes[0,1].axhline(y=0.8, color='red', linestyle='--', label='æ¨å¥¨æ¤œå‡ºåŠ›(0.8)')
                axes[0,1].set_title('Ï‡Â²æ¤œå®šã®æ¤œå‡ºåŠ›')
                axes[0,1].set_ylabel('æ¤œå‡ºåŠ›')
                axes[0,1].legend()
                axes[0,1].set_ylim(0, 1)
                axes[0,1].tick_params(axis='x', rotation=45)
        
        # ç›¸é–¢åˆ†ææ¤œå‡ºåŠ›
        if 'correlation_tests' in self.results['power_analysis']:
            corr_tests = self.results['power_analysis']['correlation_tests']
            
            valid_tests = {k: v for k, v in corr_tests.items() if 'error' not in v}
            if valid_tests:
                test_names = [name.replace('_vs_', ' - ') for name in valid_tests.keys()]
                powers = [valid_tests[list(valid_tests.keys())[i]]['power'] for i in range(len(test_names))]
                
                axes[1,0].bar(test_names, powers, color='lightgreen', alpha=0.7)
                axes[1,0].axhline(y=0.8, color='red', linestyle='--', label='æ¨å¥¨æ¤œå‡ºåŠ›(0.8)')
                axes[1,0].set_title('ç›¸é–¢åˆ†æã®æ¤œå‡ºåŠ›')
                axes[1,0].set_ylabel('æ¤œå‡ºåŠ›')
                axes[1,0].legend()
                axes[1,0].set_ylim(0, 1)
                axes[1,0].tick_params(axis='x', rotation=45)
        
        # æ¤œå‡ºåŠ›ã‚µãƒãƒªãƒ¼
        all_powers = []
        if 't_tests' in self.results['power_analysis']:
            all_powers.extend([v['power'] for v in self.results['power_analysis']['t_tests'].values()])
        
        if all_powers:
            axes[1,1].hist(all_powers, bins=10, alpha=0.7, color='purple')
            axes[1,1].axvline(x=0.8, color='red', linestyle='--', label='æ¨å¥¨æ¤œå‡ºåŠ›(0.8)')
            axes[1,1].set_title('æ¤œå‡ºåŠ›åˆ†å¸ƒ')
            axes[1,1].set_xlabel('æ¤œå‡ºåŠ›')
            axes[1,1].set_ylabel('é »åº¦')
            axes[1,1].legend()
        
        plt.tight_layout()
        
        output_path = self.figures_dir / "power_analysis_results.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ æ¤œå‡ºåŠ›åˆ†æå›³ä¿å­˜: {output_path}")
    
    def _create_effect_size_plot(self):
        """åŠ¹æœé‡å¯è¦–åŒ–"""
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        # Cohen's dï¼ˆé€£ç¶šå¤‰æ•°ï¼‰
        if 'effect_sizes' in self.results:
            es_data = self.results['effect_sizes']
            
            if 'q1_composite' in es_data and 'q3_composite' in es_data:
                variables = ['Q1ç·åˆã‚¹ã‚³ã‚¢', 'Q3ç·åˆã‚¹ã‚³ã‚¢']
                cohens_d = [es_data['q1_composite']['cohens_d'], es_data['q3_composite']['cohens_d']]
                
                colors = ['blue' if d > 0 else 'red' for d in cohens_d]
                bars = axes[0].bar(variables, cohens_d, color=colors, alpha=0.7)
                axes[0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
                axes[0].axhline(y=0.2, color='green', linestyle='--', alpha=0.5, label='å°åŠ¹æœ(0.2)')
                axes[0].axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='ä¸­åŠ¹æœ(0.5)')
                axes[0].axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='å¤§åŠ¹æœ(0.8)')
                axes[0].set_title("Cohen's d (åŠ¹æœé‡)")
                axes[0].set_ylabel("Cohen's d")
                axes[0].legend()
                
                # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
                for bar, d in zip(bars, cohens_d):
                    height = bar.get_height()
                    axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.01 if height >= 0 else height - 0.05,
                               f'{d:.3f}', ha='center', va='bottom' if height >= 0 else 'top')
        
        # CramÃ©r's Vï¼ˆã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ï¼‰
        if 'categorical' in self.results['effect_sizes']:
            cat_data = self.results['effect_sizes']['categorical']
            valid_items = {k: v for k, v in cat_data.items() if 'error' not in v}
            
            if valid_items:
                items = list(valid_items.keys())
                cramers_v = [valid_items[item]['cramers_v'] for item in items]
                
                axes[1].bar(items, cramers_v, color='skyblue', alpha=0.7)
                axes[1].axhline(y=0.1, color='green', linestyle='--', alpha=0.5, label='å°åŠ¹æœ(0.1)')
                axes[1].axhline(y=0.3, color='orange', linestyle='--', alpha=0.5, label='ä¸­åŠ¹æœ(0.3)')
                axes[1].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='å¤§åŠ¹æœ(0.5)')
                axes[1].set_title("CramÃ©r's V (ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åŠ¹æœé‡)")
                axes[1].set_ylabel("CramÃ©r's V")
                axes[1].legend()
                axes[1].tick_params(axis='x', rotation=45)
        
        # åŠ¹æœé‡æ¯”è¼ƒã‚µãƒãƒªãƒ¼
        effect_summary_data = []
        effect_labels = []
        
        if 'effect_sizes' in self.results:
            es_data = self.results['effect_sizes']
            
            if 'q1_composite' in es_data:
                effect_summary_data.append(abs(es_data['q1_composite']['cohens_d']))
                effect_labels.append('Q1 (Cohen\'s d)')
            
            if 'q3_composite' in es_data:
                effect_summary_data.append(abs(es_data['q3_composite']['cohens_d']))
                effect_labels.append('Q3 (Cohen\'s d)')
            
            if 'categorical' in es_data:
                for item, data in es_data['categorical'].items():
                    if 'error' not in data:
                        effect_summary_data.append(data['cramers_v'])
                        effect_labels.append(f'{item} (CramÃ©r\'s V)')
        
        if effect_summary_data:
            axes[2].barh(effect_labels, effect_summary_data, alpha=0.7)
            axes[2].axvline(x=0.2, color='green', linestyle='--', alpha=0.5, label='å°åŠ¹æœ')
            axes[2].axvline(x=0.5, color='orange', linestyle='--', alpha=0.5, label='ä¸­åŠ¹æœ')
            axes[2].axvline(x=0.8, color='red', linestyle='--', alpha=0.5, label='å¤§åŠ¹æœ')
            axes[2].set_title('åŠ¹æœé‡ä¸€è¦§')
            axes[2].set_xlabel('åŠ¹æœé‡')
            axes[2].legend()
        
        plt.tight_layout()
        
        output_path = self.figures_dir / "effect_sizes_summary.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ åŠ¹æœé‡å›³ä¿å­˜: {output_path}")
    
    def _create_sample_size_recommendation_plot(self):
        """ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºæ¨å¥¨ãƒ—ãƒ­ãƒƒãƒˆ"""
        if 'sample_size_recommendations' not in self.results:
            return
        
        recommendations = self.results['sample_size_recommendations']
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # åŠ¹æœé‡åˆ¥å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
        effect_sizes = []
        t_test_ns = []
        
        for key, data in recommendations.items():
            effect_sizes.append(data['effect_size'])
            t_test_ns.append(data['t_test_n_per_group'])
        
        ax1.plot(effect_sizes, t_test_ns, 'o-', linewidth=2, markersize=8, label='tæ¤œå®šï¼ˆç¾¤ã‚ãŸã‚Šï¼‰')
        ax1.axhline(y=99, color='red', linestyle='--', alpha=0.7, label='ç¾åœ¨ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º')
        ax1.set_xlabel('åŠ¹æœé‡ (Cohen\'s d)')
        ax1.set_ylabel('å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆç¾¤ã‚ãŸã‚Šï¼‰')
        ax1.set_title('åŠ¹æœé‡åˆ¥å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º\n(æ¤œå‡ºåŠ›=0.8, Î±=0.05)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ç¾åœ¨ã®åˆ†æã®æ¤œå‡ºåŠ›è©•ä¾¡
        current_powers = []
        current_labels = []
        
        if 'power_analysis' in self.results:
            if 't_tests' in self.results['power_analysis']:
                for test_name, test_data in self.results['power_analysis']['t_tests'].items():
                    current_powers.append(test_data['power'])
                    current_labels.append(test_name)
        
        if current_powers:
            colors = ['green' if p >= 0.8 else 'orange' if p >= 0.6 else 'red' for p in current_powers]
            bars = ax2.bar(current_labels, current_powers, color=colors, alpha=0.7)
            ax2.axhline(y=0.8, color='red', linestyle='--', label='æ¨å¥¨æ¤œå‡ºåŠ›(0.8)')
            ax2.set_title('ç¾åœ¨ã®åˆ†æã®æ¤œå‡ºåŠ›è©•ä¾¡')
            ax2.set_ylabel('æ¤œå‡ºåŠ›')
            ax2.legend()
            ax2.set_ylim(0, 1)
            
            # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
            for bar, power in zip(bars, current_powers):
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                        f'{power:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        
        output_path = self.figures_dir / "sample_size_recommendations.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºæ¨å¥¨å›³ä¿å­˜: {output_path}")
    
    def _create_bootstrap_plot(self):
        """Bootstrapä¿¡é ¼åŒºé–“ãƒ—ãƒ­ãƒƒãƒˆ"""
        if 'bootstrap_analysis' not in self.results:
            return
        
        bootstrap_data = self.results['bootstrap_analysis']
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # Q1 Bootstrapåˆ†å¸ƒ
        if 'q1_composite' in bootstrap_data:
            q1_data = bootstrap_data['q1_composite']
            
            # åˆ†å¸ƒã‚’ãƒ—ãƒ­ãƒƒãƒˆï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
            # Bootstrapåˆ†å¸ƒã¯å®Ÿéš›ã«ã¯ä¿å­˜ã—ã¦ã„ãªã„ã®ã§ã€æ­£è¦åˆ†å¸ƒã§è¿‘ä¼¼
            x_range = np.linspace(q1_data['ci_95_lower'] - 0.5, q1_data['ci_95_upper'] + 0.5, 100)
            y_values = stats.norm.pdf(x_range, q1_data['bootstrap_mean'], q1_data['bootstrap_std'])
            
            axes[0].plot(x_range, y_values, 'b-', linewidth=2, label='Bootstrapåˆ†å¸ƒ')
            axes[0].axvline(q1_data['observed_difference'], color='red', linestyle='-', 
                          linewidth=2, label=f'è¦³æ¸¬å€¤ ({q1_data["observed_difference"]:.3f})')
            axes[0].axvline(q1_data['ci_95_lower'], color='green', linestyle='--', 
                          label=f'95%CIä¸‹é™ ({q1_data["ci_95_lower"]:.3f})')
            axes[0].axvline(q1_data['ci_95_upper'], color='green', linestyle='--', 
                          label=f'95%CIä¸Šé™ ({q1_data["ci_95_upper"]:.3f})')
            axes[0].axvline(0, color='black', linestyle=':', alpha=0.5, label='å·®ãªã—')
            
            axes[0].set_title('Q1ç·åˆã‚¹ã‚³ã‚¢å·®ã® Bootstrapä¿¡é ¼åŒºé–“')
            axes[0].set_xlabel('å¹³å‡ã‚¹ã‚³ã‚¢å·®')
            axes[0].set_ylabel('ç¢ºç‡å¯†åº¦')
            axes[0].legend()
            axes[0].grid(True, alpha=0.3)
        
        # Q3 Bootstrapåˆ†å¸ƒ
        if 'q3_composite' in bootstrap_data:
            q3_data = bootstrap_data['q3_composite']
            
            x_range = np.linspace(q3_data['ci_95_lower'] - 0.5, q3_data['ci_95_upper'] + 0.5, 100)
            y_values = stats.norm.pdf(x_range, q3_data['bootstrap_mean'], q3_data['bootstrap_std'])
            
            axes[1].plot(x_range, y_values, 'b-', linewidth=2, label='Bootstrapåˆ†å¸ƒ')
            axes[1].axvline(q3_data['observed_difference'], color='red', linestyle='-', 
                          linewidth=2, label=f'è¦³æ¸¬å€¤ ({q3_data["observed_difference"]:.3f})')
            axes[1].axvline(q3_data['ci_95_lower'], color='green', linestyle='--', 
                          label=f'95%CIä¸‹é™ ({q3_data["ci_95_lower"]:.3f})')
            axes[1].axvline(q3_data['ci_95_upper'], color='green', linestyle='--', 
                          label=f'95%CIä¸Šé™ ({q3_data["ci_95_upper"]:.3f})')
            axes[1].axvline(0, color='black', linestyle=':', alpha=0.5, label='å·®ãªã—')
            
            axes[1].set_title('Q3ç·åˆã‚¹ã‚³ã‚¢å·®ã® Bootstrapä¿¡é ¼åŒºé–“')
            axes[1].set_xlabel('å¹³å‡ã‚¹ã‚³ã‚¢å·®')
            axes[1].set_ylabel('ç¢ºç‡å¯†åº¦')
            axes[1].legend()
            axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        output_path = self.figures_dir / "bootstrap_confidence_intervals.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ Bootstrapä¿¡é ¼åŒºé–“å›³ä¿å­˜: {output_path}")
    
    def generate_recommendations(self):
        """çµ±è¨ˆçš„æè¨€ç”Ÿæˆ"""
        print("\nğŸ“ çµ±è¨ˆçš„æè¨€ç”Ÿæˆä¸­...")
        
        recommendations = {
            'current_analysis_evaluation': self._evaluate_current_analysis(),
            'future_study_design': self._design_future_study(),
            'statistical_best_practices': self._statistical_best_practices(),
            'reporting_guidelines': self._reporting_guidelines()
        }
        
        self.results['recommendations'] = recommendations
        
        print("âœ“ çµ±è¨ˆçš„æè¨€ç”Ÿæˆå®Œäº†")
    
    def _evaluate_current_analysis(self):
        """ç¾åœ¨ã®åˆ†æè©•ä¾¡"""
        evaluation = {
            'strengths': [
                "é©åˆ‡ãªç‹¬ç«‹ç¾¤æ¯”è¼ƒè¨­è¨ˆã®æ¡ç”¨",
                "å¤šé‡æ¯”è¼ƒè£œæ­£ã®å®Ÿæ–½",
                "åŠ¹æœé‡ã®å ±å‘Š",
                "éãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¤œå®šã®ä½µç”¨"
            ],
            'limitations': [
                f"é™å®šçš„ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆN={len(self.before_data)}, {len(self.after_data)}ï¼‰",
                "ä¸€éƒ¨æ¤œå®šã§ã®æ¤œå‡ºåŠ›ä¸è¶³",
                "å€‹äººè¿½è·¡ä¸å¯ã«ã‚ˆã‚‹åˆ¶ç´„",
                "è¦³å¯Ÿç ”ç©¶ã¨ã—ã¦ã®å› æœæ¨è«–ã®é™ç•Œ"
            ],
            'power_summary': self._summarize_power_results()
        }
        
        return evaluation
    
    def _summarize_power_results(self):
        """æ¤œå‡ºåŠ›çµæœè¦ç´„"""
        if 'power_analysis' not in self.results:
            return "æ¤œå‡ºåŠ›åˆ†ææœªå®Ÿæ–½"
        
        power_data = self.results['power_analysis']
        summary = {}
        
        # tæ¤œå®šæ¤œå‡ºåŠ›è¦ç´„
        if 't_tests' in power_data:
            t_powers = [test['power'] for test in power_data['t_tests'].values()]
            summary['t_tests'] = {
                'mean_power': np.mean(t_powers),
                'adequate_power_count': sum(1 for p in t_powers if p >= 0.8),
                'total_tests': len(t_powers)
            }
        
        return summary
    
    def _design_future_study(self):
        """å°†æ¥ç ”ç©¶è¨­è¨ˆæè¨€"""
        future_design = {
            'recommended_sample_size': self._recommend_sample_size(),
            'design_improvements': [
                "å€‹äººè­˜åˆ¥å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ å°å…¥",
                "ãƒ©ãƒ³ãƒ€ãƒ å‰²ä»˜ã«ã‚ˆã‚‹å®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³",
                "çµ±åˆ¶ç¾¤ã®è¨­å®š",
                "é•·æœŸè¿½è·¡èª¿æŸ»ã®å®Ÿæ–½",
                "å¤šå¤‰é‡èª¿æ•´ã«ã‚ˆã‚‹äº¤çµ¡åˆ¶å¾¡"
            ],
            'data_collection_enhancements': [
                "ã‚ˆã‚Šè©³ç´°ãªèƒŒæ™¯å¤‰æ•°åé›†",
                "ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä½“ç³»çš„åé›†",
                "æˆæ¥­å®Ÿæ–½æ¡ä»¶ã®æ¨™æº–åŒ–",
                "æ•™å¸«è¦å› ã®çµ±åˆ¶ãƒ»æ¸¬å®š"
            ],
            'analysis_strategy': [
                "éšå±¤ç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆHLMï¼‰ã®é©ç”¨",
                "å‚¾å‘ã‚¹ã‚³ã‚¢ãƒãƒƒãƒãƒ³ã‚°",
                "æ§‹é€ æ–¹ç¨‹å¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ç™ºå±•",
                "æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã¨ã®çµ±åˆ"
            ]
        }
        
        return future_design
    
    def _recommend_sample_size(self):
        """æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º"""
        if 'sample_size_recommendations' not in self.results:
            return "ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—æœªå®Ÿæ–½"
        
        recommendations = self.results['sample_size_recommendations']
        
        # ä¸­åŠ¹æœï¼ˆ0.5ï¼‰ã§ã®æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
        medium_effect = recommendations.get('effect_size_0.5', {})
        
        return {
            'target_effect_size': 0.5,
            'recommended_n_per_group': medium_effect.get('t_test_n_per_group', 'N/A'),
            'current_n_per_group': len(self.before_data),
            'improvement_needed': medium_effect.get('t_test_n_per_group', 0) > len(self.before_data)
        }
    
    def _statistical_best_practices(self):
        """çµ±è¨ˆçš„ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹"""
        practices = {
            'effect_size_reporting': [
                "ã™ã¹ã¦ã®æ¤œå®šã§åŠ¹æœé‡ã‚’å ±å‘Š",
                "å®Ÿè³ªçš„æ„å‘³ã®ã‚ã‚‹åŠ¹æœã‚µã‚¤ã‚ºã®é–¾å€¤è¨­å®š",
                "ä¿¡é ¼åŒºé–“ã®ä½µè¨˜"
            ],
            'multiple_testing': [
                "äº‹å‰ã®æ¤œå®šè¨ˆç”»ç«‹æ¡ˆ",
                "é©åˆ‡ãªå¤šé‡æ¯”è¼ƒè£œæ­£æ³•é¸æŠ",
                "æ¢ç´¢çš„åˆ†æã¨ç¢ºèªçš„åˆ†æã®åŒºåˆ¥"
            ],
            'model_validation': [
                "çµ±è¨ˆçš„å‰ææ¡ä»¶ã®ç¢ºèª",
                "ãƒ­ãƒã‚¹ãƒˆæ€§ãƒã‚§ãƒƒã‚¯",
                "æ„Ÿåº¦åˆ†æã®å®Ÿæ–½"
            ]
        }
        
        return practices
    
    def _reporting_guidelines(self):
        """å ±å‘Šã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³"""
        guidelines = {
            'required_elements': [
                "ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¨ãã®æ ¹æ‹ ",
                "åŠ¹æœé‡ã¨ä¿¡é ¼åŒºé–“",
                "æ¤œå‡ºåŠ›ã¾ãŸã¯æ¤œå‡ºåŠ›åˆ†æçµæœ",
                "å¤šé‡æ¯”è¼ƒè£œæ­£ã®è©³ç´°",
                "åˆ†æã®é™ç•Œã¨è§£é‡ˆä¸Šã®æ³¨æ„"
            ],
            'transparency_measures': [
                "äº‹å‰åˆ†æè¨ˆç”»ã®å…¬é–‹",
                "ãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨å¯èƒ½æ€§",
                "åˆ†æã‚³ãƒ¼ãƒ‰ã®å…±æœ‰",
                "çµæœã®å†ç¾æ€§ç¢ºä¿"
            ],
            'interpretation_cautions': [
                "å› æœæ¨è«–ã®é™ç•Œæ˜è¨˜",
                "ä¸€èˆ¬åŒ–å¯èƒ½æ€§ã®æ¤œè¨",
                "å®Ÿè·µçš„æ„ç¾©ã®è©•ä¾¡",
                "çµ±è¨ˆçš„æœ‰æ„æ€§ã¨å®Ÿè³ªçš„æ„ç¾©ã®åŒºåˆ¥"
            ]
        }
        
        return guidelines
    
    def save_results(self):
        """çµæœä¿å­˜"""
        print("\nğŸ’¾ çµæœä¿å­˜ä¸­...")
        
        # è©³ç´°çµæœ
        detailed_results = {
            'metadata': {
                'analysis_type': 'Power Analysis and Statistical Validation',
                'generated_at': datetime.now().isoformat(),
                'sample_size_before': len(self.before_data),
                'sample_size_after': len(self.after_data)
            },
            'effect_sizes': self.results.get('effect_sizes', {}),
            'power_analysis': self.results.get('power_analysis', {}),
            'sample_size_recommendations': self.results.get('sample_size_recommendations', {}),
            'bootstrap_analysis': self.results.get('bootstrap_analysis', {}),
            'recommendations': self.results.get('recommendations', {})
        }
        
        # JSONä¿å­˜
        output_path = self.output_dir / "power_analysis_results.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ“ è©³ç´°çµæœä¿å­˜: {output_path}")
        
        # è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        self._create_summary_report(detailed_results)
    
    def _create_summary_report(self, detailed_results):
        """è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        report_lines = [
            "# çµ±è¨ˆçš„æ¤œå‡ºåŠ›åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
            "## å°å­¦æ ¡å‡ºå‰æˆæ¥­ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ - çµ±è¨ˆçš„å¦¥å½“æ€§æ¤œè¨¼",
            "",
            f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º**: æˆæ¥­å‰ {detailed_results['metadata']['sample_size_before']} ä»¶, æˆæ¥­å¾Œ {detailed_results['metadata']['sample_size_after']} ä»¶",
            "",
            "## åˆ†ææ¦‚è¦",
            "",
            "å®Ÿæ–½ã—ãŸçµ±è¨ˆåˆ†æã®æ¤œå‡ºåŠ›ã‚’è©•ä¾¡ã—ã€å°†æ¥ã®ç ”ç©¶è¨­è¨ˆã¸ã®æè¨€ã‚’æä¾›ã€‚",
            "åŠ¹æœé‡ã€Bootstrapä¿¡é ¼åŒºé–“ã€å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’åŒ…æ‹¬çš„ã«æ¤œè¨ã€‚",
            ""
        ]
        
        # åŠ¹æœé‡ã‚µãƒãƒªãƒ¼
        if 'effect_sizes' in detailed_results:
            report_lines.extend([
                "## åŠ¹æœé‡ã‚µãƒãƒªãƒ¼",
                ""
            ])
            
            effect_sizes = detailed_results['effect_sizes']
            
            if 'q1_composite' in effect_sizes:
                q1 = effect_sizes['q1_composite']
                report_lines.append(f"**Q1ç·åˆã‚¹ã‚³ã‚¢**: Cohen's d = {q1['cohens_d']:.3f}")
            
            if 'q3_composite' in effect_sizes:
                q3 = effect_sizes['q3_composite']
                report_lines.append(f"**Q3ç·åˆã‚¹ã‚³ã‚¢**: Cohen's d = {q3['cohens_d']:.3f}")
            
            report_lines.append("")
        
        # æ¤œå‡ºåŠ›è©•ä¾¡
        if 'power_analysis' in detailed_results:
            report_lines.extend([
                "## æ¤œå‡ºåŠ›è©•ä¾¡",
                ""
            ])
            
            power_data = detailed_results['power_analysis']
            
            if 't_tests' in power_data:
                report_lines.append("### tæ¤œå®šã®æ¤œå‡ºåŠ›")
                report_lines.append("")
                
                for test_name, test_data in power_data['t_tests'].items():
                    status = test_data['interpretation']
                    report_lines.append(f"- **{test_name}**: {test_data['power']:.3f} ({status})")
                
                report_lines.append("")
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºæ¨å¥¨
        if 'sample_size_recommendations' in detailed_results:
            report_lines.extend([
                "## å°†æ¥ç ”ç©¶ã¸ã®æ¨å¥¨ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º",
                "",
                "| åŠ¹æœé‡ | åŠ¹æœã®è§£é‡ˆ | å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºï¼ˆç¾¤ã‚ãŸã‚Šï¼‰ | æ¤œå‡ºåŠ› |",
                "|--------|------------|--------------------------------|--------|"
            ])
            
            for key, rec in detailed_results['sample_size_recommendations'].items():
                if 'effect_size' in rec:
                    report_lines.append(
                        f"| {rec['effect_size']} | {rec['effect_interpretation']} | "
                        f"{rec['t_test_n_per_group']:.0f} | {rec['power']} |"
                    )
            
            report_lines.append("")
        
        # Bootstrapä¿¡é ¼åŒºé–“
        if 'bootstrap_analysis' in detailed_results:
            report_lines.extend([
                "## Bootstrapä¿¡é ¼åŒºé–“ï¼ˆ95%ï¼‰",
                ""
            ])
            
            bootstrap_data = detailed_results['bootstrap_analysis']
            
            for variable, data in bootstrap_data.items():
                if 'ci_95_lower' in data:
                    significance = "æœ‰æ„" if data['significant'] else "éæœ‰æ„"
                    report_lines.append(
                        f"**{variable}**: [{data['ci_95_lower']:.3f}, {data['ci_95_upper']:.3f}] ({significance})"
                    )
            
            report_lines.append("")
        
        # æè¨€
        if 'recommendations' in detailed_results:
            recs = detailed_results['recommendations']
            
            report_lines.extend([
                "## çµ±è¨ˆçš„æè¨€",
                "",
                "### ç¾åœ¨ã®åˆ†æã®è©•ä¾¡",
                ""
            ])
            
            if 'current_analysis_evaluation' in recs:
                eval_data = recs['current_analysis_evaluation']
                
                if 'strengths' in eval_data:
                    report_lines.append("**å¼·ã¿:**")
                    for strength in eval_data['strengths']:
                        report_lines.append(f"- {strength}")
                    report_lines.append("")
                
                if 'limitations' in eval_data:
                    report_lines.append("**åˆ¶ç´„äº‹é …:**")
                    for limitation in eval_data['limitations']:
                        report_lines.append(f"- {limitation}")
                    report_lines.append("")
            
            if 'future_study_design' in recs:
                future_design = recs['future_study_design']
                
                report_lines.extend([
                    "### å°†æ¥ç ”ç©¶ã¸ã®æè¨€",
                    ""
                ])
                
                if 'design_improvements' in future_design:
                    report_lines.append("**ãƒ‡ã‚¶ã‚¤ãƒ³æ”¹å–„:**")
                    for improvement in future_design['design_improvements']:
                        report_lines.append(f"- {improvement}")
                    report_lines.append("")
        
        # çµè«–
        report_lines.extend([
            "## çµè«–",
            "",
            "æœ¬åˆ†æã¯ç‹¬ç«‹ç¾¤æ¯”è¼ƒã¨ã—ã¦é©åˆ‡ã«å®Ÿæ–½ã•ã‚Œã¾ã—ãŸãŒã€æ¤œå‡ºåŠ›ã®è¦³ç‚¹ã‹ã‚‰æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ã€‚",
            "å°†æ¥ã®ç ”ç©¶ã§ã¯ã€ã‚ˆã‚Šå¤§ããªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã¨å€‹äººè¿½è·¡å¯èƒ½ãªç ”ç©¶ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
            "",
            "---",
            "",
            "**Generated by**: Claude Code Analysis (Power Analysis Implementation)",
            f"**Output Files**: {self.output_dir}",
            f"**Figures**: {self.figures_dir}"
        ])
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = self.output_dir / "power_analysis_summary.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"âœ“ è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    
    def run_complete_analysis(self):
        """å®Œå…¨æ¤œå‡ºåŠ›åˆ†æå®Ÿè¡Œ"""
        print("="*60)
        print("çµ±è¨ˆçš„æ¤œå‡ºåŠ›åˆ†æã¨ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—")
        print("="*60)
        print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        try:
            # åˆ†æå®Ÿè¡Œ
            self.load_data_and_results()
            self.calculate_effect_sizes()
            self.calculate_post_hoc_power()
            self.calculate_required_sample_sizes()
            self.bootstrap_confidence_intervals()
            self.create_visualizations()
            self.generate_recommendations()
            self.save_results()
            
            print("\n" + "="*60)
            print("ğŸ‰ æ¤œå‡ºåŠ›åˆ†æå®Œäº†!")
            print("="*60)
            print(f"çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print()
            print("ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
            print(f"  - è©³ç´°çµæœ: {self.output_dir}/power_analysis_results.json")
            print(f"  - è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆ: {self.output_dir}/power_analysis_summary.txt")
            print(f"  - å›³è¡¨: {self.figures_dir}/")
            print()
            print("ğŸ“Š ä¸»è¦ãªç™ºè¦‹:")
            
            # ä¸»è¦çµæœã®è¡¨ç¤º
            if hasattr(self, 'results') and 'effect_sizes' in self.results:
                if 'q1_composite' in self.results['effect_sizes']:
                    q1_d = self.results['effect_sizes']['q1_composite']['cohens_d']
                    print(f"  - Q1ç·åˆã‚¹ã‚³ã‚¢åŠ¹æœé‡: Cohen's d = {q1_d:.3f}")
                
                if 'q3_composite' in self.results['effect_sizes']:
                    q3_d = self.results['effect_sizes']['q3_composite']['cohens_d']
                    print(f"  - Q3ç·åˆã‚¹ã‚³ã‚¢åŠ¹æœé‡: Cohen's d = {q3_d:.3f}")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ æ¤œå‡ºåŠ›åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            print(f"è©³ç´°: {traceback.format_exc()}")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_root = Path(__file__).parent.parent.parent
    
    analyzer = PowerAnalysisEvaluator(project_root)
    
    try:
        success = analyzer.run_complete_analysis()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()