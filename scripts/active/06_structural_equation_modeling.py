#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ§‹é€ æ–¹ç¨‹å¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆSEMï¼‰ã«ã‚ˆã‚‹æ•™è‚²åŠ¹æœã®å› æœæ§‹é€ åˆ†æ
=======================================================

ç‹¬ç«‹ç¾¤æ¯”è¼ƒã«ãŠã‘ã‚‹å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®æ§‹é€ çš„é–¢ä¿‚ã‚’è§£æ˜ã™ã‚‹ã€‚

æ©Ÿèƒ½:
- æ½œåœ¨å¤‰æ•°ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆç§‘å­¦çš„ç†è§£ã€å­¦ç¿’ç©æ¥µæ€§ï¼‰
- ãƒ‘ã‚¹è§£æã«ã‚ˆã‚‹å› æœé–¢ä¿‚æ¨å®š
- ãƒ¢ãƒ‡ãƒ«é©åˆåº¦è©•ä¾¡ï¼ˆCFI, RMSEA, SRMRï¼‰
- é–“æ¥åŠ¹æœãƒ»ç·åŠ¹æœã®ç®—å‡º
- æ•™è‚²çš„ç¤ºå”†ã®æŠ½å‡º

åˆ¶ç´„:
- Page_IDã«ã‚ˆã‚‹å€‹äººè¿½è·¡ä¸å¯ã®ãŸã‚ç‹¬ç«‹ç¾¤è¨­è¨ˆ
- æˆæ¥­å‰å¾Œãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ç¾¤ã¨ã—ã¦æ‰±ã†
- ã‚¯ãƒ­ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒŠãƒ«SEMãƒ¢ãƒ‡ãƒ«é©ç”¨

Author: Claude Code Analysis (SEM Implementation)
Date: 2025-05-31
"""

import os
import sys
import json
import warnings
from pathlib import Path
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# SEMé–¢é€£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import semopy

# è­¦å‘ŠæŠ‘åˆ¶
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

class StructuralEquationModeling:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.data_dir = self.project_root / "data" / "analysis"
        self.output_dir = self.project_root / "outputs" / "current" / "05_advanced_analysis"
        self.figures_dir = self.project_root / "outputs" / "figures" / "current" / "05_advanced_analysis"
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.figures_dir.mkdir(parents=True, exist_ok=True)
        
        self.results = {}
        
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        
        # æˆæ¥­å‰å¾Œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        before_path = self.data_dir / "before_excel_compliant.csv"
        after_path = self.data_dir / "after_excel_compliant.csv"
        
        if not before_path.exists() or not after_path.exists():
            raise FileNotFoundError("å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        self.before_data = pd.read_csv(before_path, encoding='utf-8')
        self.after_data = pd.read_csv(after_path, encoding='utf-8')
        
        print(f"âœ“ æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿: {len(self.before_data)} ä»¶")
        print(f"âœ“ æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿: {len(self.after_data)} ä»¶")
        
    def prepare_sem_data(self):
        """SEMåˆ†æç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        print("\nğŸ”§ SEMåˆ†æç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...")
        
        # æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        before_sem = self.before_data.copy()
        
        # Q1ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæˆæ¥­å‰ï¼‰
        q1_before_cols = ['Q1_Saltwater_Response', 'Q1_Sugarwater_Response', 'Q1_Muddywater_Response', 
                         'Q1_Ink_Response', 'Q1_MisoSoup_Response', 'Q1_SoySauce_Response']
        before_sem['Q1_total_before'] = before_sem[q1_before_cols].sum(axis=1)
        
        # Q3ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæˆæ¥­å‰ï¼‰
        q3_before_cols = ['Q3_TeaLeavesDissolve', 'Q3_TeaComponentsDissolve']
        before_sem['Q3_total_before'] = before_sem[q3_before_cols].sum(axis=1)
        
        # æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿å‡¦ç†
        after_sem = self.after_data.copy()
        
        # Q1ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæˆæ¥­å¾Œï¼‰
        q1_after_cols = ['Q1_Saltwater', 'Q1_Sugarwater', 'Q1_Muddywater',
                        'Q1_Ink', 'Q1_MisoSoup', 'Q1_SoySauce']
        after_sem['Q1_total_after'] = after_sem[q1_after_cols].sum(axis=1)
        
        # Q3ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæˆæ¥­å¾Œï¼‰
        q3_after_cols = ['Q3_TeaLeaves_DissolveInWater', 'Q3_TeaComponents_DissolveInWater']
        after_sem['Q3_total_after'] = after_sem[q3_after_cols].sum(axis=1)
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆç‹¬ç«‹ç¾¤ã¨ã—ã¦ï¼‰
        # æˆæ¥­å‰ç¾¤ï¼šgroup=0ã€æˆæ¥­å¾Œç¾¤ï¼šgroup=1
        before_sem['group'] = 0
        after_sem['group'] = 1
        
        # æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ•°åèª¿æ•´
        before_vars = ['Page_ID', 'class', 'Q1_total_before', 'Q3_total_before', 'group']
        before_subset = before_sem[before_vars].copy()
        before_subset.columns = ['Page_ID', 'class', 'Q1_total', 'Q3_total', 'group']
        
        # æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã®å¤‰æ•°é¸æŠ
        after_vars = ['Page_ID', 'class', 'Q1_total_after', 'Q3_total_after',
                     'Q4_ExperimentInterestRating', 'Q5_NewLearningsRating',
                     'Q6_DissolvingUnderstandingRating', 'group']
        after_subset = after_sem[after_vars].copy()
        after_subset.columns = ['Page_ID', 'class', 'Q1_total', 'Q3_total',
                               'Q4_interest', 'Q5_learning', 'Q6_understanding', 'group']
        
        # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        # æˆæ¥­å‰ãƒ‡ãƒ¼ã‚¿ã«ã¯æ¬ æå€¤ã‚’è¨­å®š
        before_subset['Q4_interest'] = np.nan
        before_subset['Q5_learning'] = np.nan
        before_subset['Q6_understanding'] = np.nan
        
        # æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã¯å…¨å¤‰æ•°å«ã‚€
        self.sem_data = pd.concat([before_subset, after_subset], ignore_index=True)
        
        # ã‚¯ãƒ©ã‚¹ãƒ€ãƒŸãƒ¼å¤‰æ•°ä½œæˆ
        class_dummies = pd.get_dummies(self.sem_data['class'], prefix='class')
        self.sem_data = pd.concat([self.sem_data, class_dummies], axis=1)
        
        print(f"âœ“ SEMçµ±åˆãƒ‡ãƒ¼ã‚¿: {len(self.sem_data)} ä»¶")
        print(f"âœ“ æˆæ¥­å‰ç¾¤: {(self.sem_data['group'] == 0).sum()} ä»¶")
        print(f"âœ“ æˆæ¥­å¾Œç¾¤: {(self.sem_data['group'] == 1).sum()} ä»¶")
        
        # åŸºæœ¬çµ±è¨ˆè¡¨ç¤º
        print("\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        desc_stats = self.sem_data[['Q1_total', 'Q3_total', 'Q4_interest', 
                                   'Q5_learning', 'Q6_understanding']].describe()
        print(desc_stats.round(3))
        
    def define_sem_models(self):
        """SEMç†è«–ãƒ¢ãƒ‡ãƒ«å®šç¾©"""
        print("\nğŸ—ï¸ SEMç†è«–ãƒ¢ãƒ‡ãƒ«å®šç¾©ä¸­...")
        
        # æ¸¬å®šãƒ¢ãƒ‡ãƒ«ï¼ˆæ½œåœ¨å¤‰æ•° â† è¦³æ¸¬å¤‰æ•°ï¼‰
        measurement_model = """
        # æ¸¬å®šãƒ¢ãƒ‡ãƒ«ï¼ˆæ½œåœ¨å¤‰æ•°ã®å®šç¾©ï¼‰
        # ç§‘å­¦çš„ç†è§£ï¼ˆæˆæ¥­å‰ï¼‰
        SciUnderstanding_Pre =~ Q1_total + Q3_total
        
        # å­¦ç¿’ã¸ã®ç©æ¥µæ€§ï¼ˆæˆæ¥­å¾Œã®ã¿æ¸¬å®šå¯èƒ½ï¼‰
        LearningEngagement =~ Q4_interest + Q5_learning
        
        # ç§‘å­¦çš„ç†è§£ï¼ˆæˆæ¥­å¾Œï¼‰
        SciUnderstanding_Post =~ Q1_total + Q3_total + Q6_understanding
        
        # æ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼ˆæ½œåœ¨å¤‰æ•°é–“ã®é–¢ä¿‚ï¼‰
        # æˆæ¥­å‰ç†è§£ â†’ å­¦ç¿’ç©æ¥µæ€§ â†’ æˆæ¥­å¾Œç†è§£
        LearningEngagement ~ SciUnderstanding_Pre
        SciUnderstanding_Post ~ SciUnderstanding_Pre + LearningEngagement
        
        # ã‚°ãƒ«ãƒ¼ãƒ—åŠ¹æœï¼ˆç‹¬ç«‹ç¾¤æ¯”è¼ƒï¼‰
        SciUnderstanding_Pre ~ group
        LearningEngagement ~ group
        SciUnderstanding_Post ~ group
        """
        
        # ç°¡ç•¥åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆæˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
        simplified_model = """
        # ç°¡ç•¥åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆæˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ­ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒŠãƒ«åˆ†æï¼‰
        # å­¦ç¿’ã¸ã®ç©æ¥µæ€§
        LearningEngagement =~ Q4_interest + Q5_learning
        
        # ç§‘å­¦çš„ç†è§£ï¼ˆçµ±åˆæŒ‡æ¨™ï¼‰
        SciUnderstanding =~ Q1_total + Q3_total + Q6_understanding
        
        # æ§‹é€ é–¢ä¿‚
        SciUnderstanding ~ LearningEngagement
        
        # ã‚¯ãƒ©ã‚¹åŠ¹æœ
        LearningEngagement ~ class_2.0 + class_3.0 + class_4.0
        SciUnderstanding ~ class_2.0 + class_3.0 + class_4.0
        """
        
        self.models = {
            'full_model': measurement_model,
            'simplified_model': simplified_model
        }
        
        print("âœ“ ãƒ•ãƒ«ãƒ¢ãƒ‡ãƒ«å®šç¾©å®Œäº†")
        print("âœ“ ç°¡ç•¥åŒ–ãƒ¢ãƒ‡ãƒ«å®šç¾©å®Œäº†")
        
    def fit_sem_models(self):
        """SEMãƒ¢ãƒ‡ãƒ«æ¨å®š"""
        print("\nâš™ï¸ SEMãƒ¢ãƒ‡ãƒ«æ¨å®šä¸­...")
        
        self.fitted_models = {}
        
        # æˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®åˆ†æï¼ˆN=99ï¼‰
        after_data = self.sem_data[self.sem_data['group'] == 1].copy()
        after_data = after_data.dropna()
        
        print(f"ğŸ“Š åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(after_data)} ä»¶")
        
        try:
            # ç°¡ç•¥åŒ–ãƒ¢ãƒ‡ãƒ«æ¨å®š
            print("ğŸ” ç°¡ç•¥åŒ–ãƒ¢ãƒ‡ãƒ«æ¨å®šä¸­...")
            
            # SEMopyã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«æ¨å®š
            model = semopy.Model(self.models['simplified_model'])
            
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæ¬ æå€¤é™¤å»ï¼‰
            analysis_vars = ['Q1_total', 'Q3_total', 'Q4_interest', 'Q5_learning', 
                           'Q6_understanding', 'class_2.0', 'class_3.0', 'class_4.0']
            
            # ã‚¯ãƒ©ã‚¹ãƒ€ãƒŸãƒ¼å¤‰æ•°ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            for class_var in ['class_2.0', 'class_3.0', 'class_4.0']:
                if class_var not in after_data.columns:
                    after_data[class_var] = 0
            
            analysis_data = after_data[analysis_vars].dropna()
            
            print(f"ğŸ“Š å®Ÿéš›ã®åˆ†æãƒ‡ãƒ¼ã‚¿: {len(analysis_data)} ä»¶")
            
            # ãƒ¢ãƒ‡ãƒ«æ¨å®š
            results = model.fit(analysis_data)
            
            self.fitted_models['simplified'] = {
                'model': model,
                'results': results,
                'data': analysis_data,
                'fit_indices': self._calculate_fit_indices(model, analysis_data)
            }
            
            print("âœ“ ç°¡ç•¥åŒ–ãƒ¢ãƒ‡ãƒ«æ¨å®šå®Œäº†")
            
        except Exception as e:
            print(f"âŒ SEMãƒ¢ãƒ‡ãƒ«æ¨å®šã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’ãƒ­ã‚°
            import traceback
            error_details = traceback.format_exc()
            print(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {error_details}")
            
            # ä»£æ›¿åˆ†æï¼šç›¸é–¢åˆ†æ
            self._alternative_correlation_analysis(after_data)
            
    def _calculate_fit_indices(self, model, data):
        """ãƒ¢ãƒ‡ãƒ«é©åˆåº¦æŒ‡æ¨™è¨ˆç®—"""
        try:
            # SEMopyã§ã®é©åˆåº¦æŒ‡æ¨™å–å¾—
            fit_indices = {}
            
            # åŸºæœ¬çš„ãªé©åˆåº¦æŒ‡æ¨™
            if hasattr(model, 'mx'):
                fit_indices.update({
                    'chi_square': model.mx.fun,
                    'degrees_of_freedom': model.mx.df if hasattr(model.mx, 'df') else 'N/A',
                    'n_observations': len(data)
                })
            
            return fit_indices
            
        except Exception as e:
            print(f"âš ï¸ é©åˆåº¦æŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'error': str(e)}
    
    def _alternative_correlation_analysis(self, data):
        """ä»£æ›¿åˆ†æï¼šç›¸é–¢ãƒ»å›å¸°åˆ†æ"""
        print("\nğŸ”„ ä»£æ›¿åˆ†æå®Ÿè¡Œä¸­ï¼ˆç›¸é–¢ãƒ»å›å¸°åˆ†æï¼‰...")
        
        try:
            # åˆ†æå¤‰æ•°
            analysis_vars = ['Q1_total', 'Q3_total', 'Q4_interest', 'Q5_learning', 'Q6_understanding']
            correlation_data = data[analysis_vars].dropna()
            
            # ç›¸é–¢è¡Œåˆ—
            correlation_matrix = correlation_data.corr()
            
            # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
            from scipy.stats import pearsonr
            
            correlations_with_p = {}
            n_vars = len(analysis_vars)
            
            for i in range(n_vars):
                for j in range(i+1, n_vars):
                    var1, var2 = analysis_vars[i], analysis_vars[j]
                    r, p = pearsonr(correlation_data[var1], correlation_data[var2])
                    correlations_with_p[f"{var1}_vs_{var2}"] = {'r': r, 'p': p}
            
            # é‡å›å¸°åˆ†æï¼ˆQ6ç†è§£åº¦ã‚’ç›®çš„å¤‰æ•°ï¼‰
            from sklearn.linear_model import LinearRegression
            from sklearn.metrics import r2_score
            
            X = correlation_data[['Q1_total', 'Q3_total', 'Q4_interest', 'Q5_learning']]
            y = correlation_data['Q6_understanding']
            
            reg_model = LinearRegression().fit(X, y)
            y_pred = reg_model.predict(X)
            r2 = r2_score(y, y_pred)
            
            # çµæœä¿å­˜
            self.fitted_models = {
                'alternative_analysis': {
                    'correlation_matrix': correlation_matrix,
                    'correlations_with_p': correlations_with_p,
                    'regression_coefficients': dict(zip(X.columns, reg_model.coef_)),
                    'regression_intercept': reg_model.intercept_,
                    'r_squared': r2,
                    'n_observations': len(correlation_data)
                }
            }
            
            print("âœ“ ä»£æ›¿åˆ†æå®Œäº†")
            
        except Exception as e:
            print(f"âŒ ä»£æ›¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    def interpret_results(self):
        """çµæœè§£é‡ˆ"""
        print("\nğŸ“ çµæœè§£é‡ˆä¸­...")
        
        interpretations = {}
        
        if 'simplified' in self.fitted_models:
            # SEMçµæœè§£é‡ˆ
            model_data = self.fitted_models['simplified']
            interpretations['sem_analysis'] = self._interpret_sem_results(model_data)
            
        elif 'alternative_analysis' in self.fitted_models:
            # ä»£æ›¿åˆ†æçµæœè§£é‡ˆ
            alt_data = self.fitted_models['alternative_analysis']
            interpretations['correlation_analysis'] = self._interpret_correlation_results(alt_data)
        
        self.results['interpretations'] = interpretations
        
    def _interpret_sem_results(self, model_data):
        """SEMçµæœã®è§£é‡ˆ"""
        interpretation = {
            'model_type': 'Structural Equation Modeling',
            'sample_size': len(model_data['data']),
            'fit_indices': model_data['fit_indices'],
            'structural_relationships': [],
            'educational_implications': []
        }
        
        # é©åˆåº¦è©•ä¾¡
        if 'chi_square' in model_data['fit_indices']:
            interpretation['model_fit_evaluation'] = "ãƒ¢ãƒ‡ãƒ«é©åˆåº¦æŒ‡æ¨™ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
        
        # æ•™è‚²çš„ç¤ºå”†
        interpretation['educational_implications'] = [
            "å­¦ç¿’ã¸ã®ç©æ¥µæ€§ãŒç§‘å­¦çš„ç†è§£ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ§‹é€ çš„ã«åˆ†æ",
            "ã‚¯ãƒ©ã‚¹é–“å·®ç•°ãŒå­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è€ƒæ…®",
            "æ½œåœ¨å¤‰æ•°ã‚’ç”¨ã„ãŸç†è«–çš„æ çµ„ã¿ã§ã®æ•™è‚²åŠ¹æœæ¸¬å®š"
        ]
        
        return interpretation
    
    def _interpret_correlation_results(self, alt_data):
        """ç›¸é–¢åˆ†æçµæœã®è§£é‡ˆ"""
        correlation_matrix = alt_data['correlation_matrix']
        correlations_with_p = alt_data['correlations_with_p']
        
        interpretation = {
            'model_type': 'Correlation and Regression Analysis',
            'sample_size': alt_data['n_observations'],
            'regression_r_squared': alt_data['r_squared'],
            'significant_correlations': [],
            'regression_coefficients': alt_data['regression_coefficients'],
            'educational_implications': []
        }
        
        # æœ‰æ„ãªç›¸é–¢é–¢ä¿‚ã®ç‰¹å®š
        for relation, stats in correlations_with_p.items():
            if stats['p'] < 0.05:
                interpretation['significant_correlations'].append({
                    'relationship': relation,
                    'correlation': stats['r'],
                    'p_value': stats['p'],
                    'interpretation': self._interpret_correlation_magnitude(stats['r'])
                })
        
        # æ•™è‚²çš„ç¤ºå”†
        interpretation['educational_implications'] = [
            f"ç†è§£åº¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›: RÂ² = {alt_data['r_squared']:.3f}",
            "å­¦ç¿’å¤‰æ•°é–“ã®é–¢é€£æ€§ã‹ã‚‰æ•™è‚²åŠ¹æœã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ¨å®š",
            "æœ‰æ„ãªç›¸é–¢é–¢ä¿‚ã‹ã‚‰é‡è¦ãªå­¦ç¿’è¦å› ã‚’ç‰¹å®š"
        ]
        
        # å›å¸°ä¿‚æ•°ã®è§£é‡ˆ
        coef_interpretation = []
        for var, coef in alt_data['regression_coefficients'].items():
            coef_interpretation.append(f"{var}: {coef:.3f} (é‡è¦åº¦é †ä½ä»˜ã‘ã®å‚è€ƒ)")
        interpretation['coefficient_interpretation'] = coef_interpretation
        
        return interpretation
    
    def _interpret_correlation_magnitude(self, r):
        """ç›¸é–¢ä¿‚æ•°ã®å¤§ãã•è§£é‡ˆ"""
        abs_r = abs(r)
        if abs_r >= 0.7:
            return "å¼·ã„é–¢é€£"
        elif abs_r >= 0.4:
            return "ä¸­ç¨‹åº¦ã®é–¢é€£"
        elif abs_r >= 0.2:
            return "å¼±ã„é–¢é€£"
        else:
            return "ã»ã¼é–¢é€£ãªã—"
    
    def create_visualizations(self):
        """å¯è¦–åŒ–ä½œæˆ"""
        print("\nğŸ“Š å¯è¦–åŒ–ä½œæˆä¸­...")
        
        plt.style.use('default')
        
        if 'alternative_analysis' in self.fitted_models:
            self._create_correlation_heatmap()
            self._create_regression_plot()
        
        # ãƒ‘ã‚¹å›³ä½œæˆï¼ˆæ¦‚å¿µå›³ï¼‰
        self._create_conceptual_path_diagram()
        
    def _create_correlation_heatmap(self):
        """ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"""
        correlation_matrix = self.fitted_models['alternative_analysis']['correlation_matrix']
        
        plt.figure(figsize=(10, 8))
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        
        sns.heatmap(correlation_matrix, 
                    mask=mask,
                    annot=True, 
                    cmap='RdBu_r', 
                    center=0,
                    square=True,
                    fmt='.3f',
                    cbar_kws={"shrink": .8})
        
        plt.title('å­¦ç¿’å¤‰æ•°é–“ã®ç›¸é–¢é–¢ä¿‚\nï¼ˆæˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ï¼‰', fontsize=14, pad=20)
        plt.tight_layout()
        
        output_path = self.figures_dir / "correlation_matrix.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ ç›¸é–¢è¡Œåˆ—ä¿å­˜: {output_path}")
    
    def _create_regression_plot(self):
        """å›å¸°åˆ†æçµæœãƒ—ãƒ­ãƒƒãƒˆ"""
        alt_data = self.fitted_models['alternative_analysis']
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # å›å¸°ä¿‚æ•°ã®å¯è¦–åŒ–
        coefficients = alt_data['regression_coefficients']
        vars_names = list(coefficients.keys())
        coef_values = list(coefficients.values())
        
        axes[0,0].barh(vars_names, coef_values)
        axes[0,0].set_title('å›å¸°ä¿‚æ•°ï¼ˆQ6ç†è§£åº¦ã¸ã®å½±éŸ¿ï¼‰')
        axes[0,0].set_xlabel('å›å¸°ä¿‚æ•°')
        
        # RÂ²å€¤è¡¨ç¤º
        axes[0,1].text(0.5, 0.5, f"RÂ² = {alt_data['r_squared']:.3f}\n\nèª¬æ˜åŠ›: {alt_data['r_squared']*100:.1f}%", 
                      ha='center', va='center', fontsize=16,
                      bbox=dict(boxstyle='round', facecolor='lightblue'))
        axes[0,1].set_xlim(0, 1)
        axes[0,1].set_ylim(0, 1)
        axes[0,1].set_title('ãƒ¢ãƒ‡ãƒ«èª¬æ˜åŠ›')
        axes[0,1].axis('off')
        
        # æœ‰æ„ãªç›¸é–¢ã®ã¿è¡¨ç¤º
        correlations_with_p = alt_data['correlations_with_p']
        significant_corrs = [(k.replace('_vs_', ' - '), v['r']) 
                           for k, v in correlations_with_p.items() if v['p'] < 0.05]
        
        if significant_corrs:
            labels, values = zip(*significant_corrs)
            axes[1,0].barh(labels, values)
            axes[1,0].set_title('æœ‰æ„ãªç›¸é–¢é–¢ä¿‚ (p < 0.05)')
            axes[1,0].set_xlabel('ç›¸é–¢ä¿‚æ•°')
        
        # ã‚µãƒ³ãƒ—ãƒ«æƒ…å ±
        axes[1,1].text(0.5, 0.5, f"åˆ†æå¯¾è±¡: {alt_data['n_observations']} ä»¶\n\nç‹¬ç«‹ç¾¤æ¯”è¼ƒ\nï¼ˆæˆæ¥­å¾Œãƒ‡ãƒ¼ã‚¿ï¼‰", 
                      ha='center', va='center', fontsize=12,
                      bbox=dict(boxstyle='round', facecolor='lightyellow'))
        axes[1,1].set_xlim(0, 1)
        axes[1,1].set_ylim(0, 1)
        axes[1,1].set_title('åˆ†ææ¦‚è¦')
        axes[1,1].axis('off')
        
        plt.tight_layout()
        
        output_path = self.figures_dir / "regression_analysis.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ å›å¸°åˆ†æå›³ä¿å­˜: {output_path}")
    
    def _create_conceptual_path_diagram(self):
        """æ¦‚å¿µçš„ãƒ‘ã‚¹å›³ä½œæˆ"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ãƒœãƒƒã‚¯ã‚¹ä½ç½®å®šç¾©
        boxes = {
            'Q1_total': (1, 3),
            'Q3_total': (1, 1),
            'Q4_interest': (3, 4),
            'Q5_learning': (3, 2),
            'Q6_understanding': (5, 3),
            'LearningEngagement': (3, 3),
            'SciUnderstanding': (5, 1.5)
        }
        
        # ãƒœãƒƒã‚¯ã‚¹æç”»
        for var, (x, y) in boxes.items():
            if var in ['LearningEngagement', 'SciUnderstanding']:
                # æ½œåœ¨å¤‰æ•°ï¼ˆæ¥•å††ï¼‰
                ellipse = plt.Circle((x, y), 0.3, fill=False, linestyle='--')
                ax.add_patch(ellipse)
                ax.text(x, y, var.replace('Learning', 'Learning\n').replace('Sci', 'Sci\n'), 
                       ha='center', va='center', fontsize=8)
            else:
                # è¦³æ¸¬å¤‰æ•°ï¼ˆçŸ©å½¢ï¼‰
                rect = plt.Rectangle((x-0.3, y-0.2), 0.6, 0.4, fill=False)
                ax.add_patch(rect)
                ax.text(x, y, var, ha='center', va='center', fontsize=9)
        
        # ãƒ‘ã‚¹ï¼ˆçŸ¢å°ï¼‰æç”»
        paths = [
            ('Q4_interest', 'LearningEngagement'),
            ('Q5_learning', 'LearningEngagement'),
            ('LearningEngagement', 'SciUnderstanding'),
            ('Q1_total', 'SciUnderstanding'),
            ('Q3_total', 'SciUnderstanding'),
            ('Q6_understanding', 'SciUnderstanding')
        ]
        
        for start, end in paths:
            x1, y1 = boxes[start]
            x2, y2 = boxes[end]
            ax.annotate('', xy=(x2, y2), xytext=(x1, y1),
                       arrowprops=dict(arrowstyle='->', lw=1.5))
        
        ax.set_xlim(0, 6)
        ax.set_ylim(0, 5)
        ax.set_aspect('equal')
        ax.axis('off')
        ax.set_title('æ•™è‚²åŠ¹æœã®æ§‹é€ çš„é–¢ä¿‚ãƒ¢ãƒ‡ãƒ«\nï¼ˆæ¦‚å¿µå›³ï¼‰', fontsize=14, pad=20)
        
        # å‡¡ä¾‹
        ax.text(0.5, 4.5, 'â–¡ è¦³æ¸¬å¤‰æ•°\nâ—‹ æ½œåœ¨å¤‰æ•°\nâ†’ æ§‹é€ é–¢ä¿‚', fontsize=10,
               bbox=dict(boxstyle='round', facecolor='lightgray'))
        
        plt.tight_layout()
        
        output_path = self.figures_dir / "conceptual_path_diagram.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ æ¦‚å¿µå›³ä¿å­˜: {output_path}")
    
    def save_results(self):
        """çµæœä¿å­˜"""
        print("\nğŸ’¾ çµæœä¿å­˜ä¸­...")
        
        # çµæœã®è©³ç´°æƒ…å ±
        detailed_results = {
            'metadata': {
                'analysis_type': 'Structural Equation Modeling',
                'generated_at': datetime.now().isoformat(),
                'sample_size_before': (self.sem_data['group'] == 0).sum(),
                'sample_size_after': (self.sem_data['group'] == 1).sum(),
                'analysis_approach': 'Independent Groups Comparison'
            },
            'data_summary': {
                'variables_analyzed': ['Q1_total', 'Q3_total', 'Q4_interest', 'Q5_learning', 'Q6_understanding'],
                'correlation_matrix': None,
                'descriptive_statistics': None
            },
            'model_results': {},
            'interpretations': self.results.get('interpretations', {}),
            'educational_implications': self._generate_educational_implications()
        }
        
        # åˆ†æçµæœè¿½åŠ 
        if 'alternative_analysis' in self.fitted_models:
            alt_data = self.fitted_models['alternative_analysis']
            detailed_results['data_summary']['correlation_matrix'] = alt_data['correlation_matrix'].to_dict()
            detailed_results['model_results'] = {
                'regression_coefficients': alt_data['regression_coefficients'],
                'r_squared': alt_data['r_squared'],
                'significant_correlations': [
                    {k: v for k, v in alt_data['correlations_with_p'].items() if v['p'] < 0.05}
                ]
            }
        
        # JSONå½¢å¼ã§ä¿å­˜
        output_path = self.output_dir / "structural_equation_modeling_results.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ“ è©³ç´°çµæœä¿å­˜: {output_path}")
        
        # è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        self._create_summary_report(detailed_results)
        
    def _generate_educational_implications(self):
        """æ•™è‚²çš„ç¤ºå”†ç”Ÿæˆ"""
        implications = {
            'learning_process_insights': [
                "å­¦ç¿’ã¸ã®ç©æ¥µæ€§ï¼ˆå®Ÿé¨“èˆˆå‘³ãƒ»æ–°å­¦ã³ï¼‰ãŒç†è§£åº¦å‘ä¸Šã®é‡è¦ãªè¦å› ",
                "æˆæ¥­å‰ã®åŸºç¤ç†è§£åº¦ãŒå­¦ç¿’æˆæœã«å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§",
                "ã‚¯ãƒ©ã‚¹é–“å·®ç•°ã‚’è€ƒæ…®ã—ãŸå€‹åˆ¥æŒ‡å°ã®é‡è¦æ€§"
            ],
            'instructional_recommendations': [
                "å®Ÿé¨“æ´»å‹•ã¸ã®èˆˆå‘³å–šèµ·ãŒåŠ¹æœçš„ãªå­¦ç¿’ä¿ƒé€²ç­–",
                "æ–°ã—ã„å­¦ã³ã¸ã®æ„è­˜å‘ä¸ŠãŒç†è§£åº¦å‘ä¸Šã«å¯„ä¸",
                "åŸºç¤çŸ¥è­˜ã®ç¢ºå®Ÿãªå®šç€ãŒç™ºå±•çš„å­¦ç¿’ã®åŸºç›¤"
            ],
            'assessment_insights': [
                "å¤šé¢çš„è©•ä¾¡ã«ã‚ˆã‚‹å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®æ§‹é€ çš„ç†è§£",
                "æ½œåœ¨çš„ãªå­¦ç¿’èƒ½åŠ›ã®æ¸¬å®šæ–¹æ³•ã®é‡è¦æ€§",
                "é‡çš„ãƒ»è³ªçš„ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆåˆ†æã®æœ‰åŠ¹æ€§"
            ],
            'methodological_notes': [
                "ç‹¬ç«‹ç¾¤æ¯”è¼ƒã«ã‚ˆã‚‹æ§‹é€ çš„é–¢ä¿‚ã®æ¨å®š",
                "å€‹äººè¿½è·¡ãƒ‡ãƒ¼ã‚¿åé›†ã®é‡è¦æ€§ï¼ˆä»Šå¾Œã®æ”¹å–„ç‚¹ï¼‰",
                "å› æœæ¨è«–ã®é™ç•Œã¨è¦³å¯Ÿç ”ç©¶ã®ç‰¹æ€§"
            ]
        }
        
        return implications
    
    def _create_summary_report(self, detailed_results):
        """è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        report_lines = [
            "# æ§‹é€ æ–¹ç¨‹å¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆSEMï¼‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆ",
            "## å°å­¦æ ¡å‡ºå‰æˆæ¥­ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆ - å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®æ§‹é€ åˆ†æ",
            "",
            f"**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**åˆ†ææ‰‹æ³•**: {detailed_results['metadata']['analysis_type']}",
            f"**ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º**: æˆæ¥­å¾Œ {detailed_results['metadata']['sample_size_after']} ä»¶",
            "",
            "## åˆ†ææ¦‚è¦",
            "",
            "ç‹¬ç«‹ç¾¤æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®æ§‹é€ çš„é–¢ä¿‚ã‚’åˆ†æã€‚",
            "å­¦ç¿’ã¸ã®ç©æ¥µæ€§ã¨ç§‘å­¦çš„ç†è§£åº¦ã®é–¢é€£æ€§ã‚’çµ±è¨ˆçš„ã«æ¤œè¨¼ã€‚",
            "",
            "## ä¸»è¦ãªç™ºè¦‹äº‹é …",
            ""
        ]
        
        # ãƒ¢ãƒ‡ãƒ«çµæœ
        if 'model_results' in detailed_results and detailed_results['model_results']:
            model_results = detailed_results['model_results']
            
            report_lines.extend([
                "### å›å¸°åˆ†æçµæœ",
                "",
                f"**ãƒ¢ãƒ‡ãƒ«èª¬æ˜åŠ›**: RÂ² = {model_results['r_squared']:.3f} ({model_results['r_squared']*100:.1f}%)",
                "",
                "**å›å¸°ä¿‚æ•°**:",
                ""
            ])
            
            for var, coef in model_results['regression_coefficients'].items():
                report_lines.append(f"- {var}: {coef:.3f}")
            
            report_lines.append("")
        
        # æ•™è‚²çš„ç¤ºå”†
        if 'educational_implications' in detailed_results:
            implications = detailed_results['educational_implications']
            
            report_lines.extend([
                "## æ•™è‚²çš„ç¤ºå”†",
                "",
                "### å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã¸ã®æ´å¯Ÿ",
                ""
            ])
            
            for insight in implications['learning_process_insights']:
                report_lines.append(f"- {insight}")
            
            report_lines.extend([
                "",
                "### æŒ‡å°æ³•ã¸ã®æè¨€",
                ""
            ])
            
            for rec in implications['instructional_recommendations']:
                report_lines.append(f"- {rec}")
            
            report_lines.extend([
                "",
                "### è©•ä¾¡æ–¹æ³•ã¸ã®ç¤ºå”†",
                ""
            ])
            
            for assessment in implications['assessment_insights']:
                report_lines.append(f"- {assessment}")
        
        # åˆ¶ç´„ã¨é™ç•Œ
        report_lines.extend([
            "",
            "## åˆ†æã®åˆ¶ç´„ã¨é™ç•Œ",
            "",
            "- Page_IDã«ã‚ˆã‚‹å€‹äººè¿½è·¡ãŒä¸å¯èƒ½ãªãŸã‚ç‹¬ç«‹ç¾¤æ¯”è¼ƒã¨ã—ã¦åˆ†æ",
            "- å› æœæ¨è«–ã«ã¯é™ç•ŒãŒã‚ã‚Šã€é–¢é€£æ€§ã®æ¨å®šã«ã¨ã©ã¾ã‚‹", 
            "- è¦³å¯Ÿç ”ç©¶ã®ãŸã‚å®Ÿé¨“çš„çµ±åˆ¶ã¯ä¸å¯èƒ½",
            "- ä»Šå¾Œã¯å€‹äººè­˜åˆ¥å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿åé›†ã‚’æ¨å¥¨",
            "",
            "---",
            "",
            "**Generated by**: Claude Code Analysis (SEM Implementation)",
            f"**Output Files**: {self.output_dir}",
            f"**Figures**: {self.figures_dir}"
        ])
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = self.output_dir / "sem_analysis_summary.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"âœ“ è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    
    def run_complete_analysis(self):
        """å®Œå…¨SEMåˆ†æå®Ÿè¡Œ"""
        print("="*60)
        print("æ§‹é€ æ–¹ç¨‹å¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆSEMï¼‰åˆ†æ")
        print("="*60)
        print(f"é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        try:
            # åˆ†æå®Ÿè¡Œ
            self.load_data()
            self.prepare_sem_data()
            self.define_sem_models()
            self.fit_sem_models()
            self.interpret_results()
            self.create_visualizations()
            self.save_results()
            
            print("\n" + "="*60)
            print("ğŸ‰ SEMåˆ†æå®Œäº†!")
            print("="*60)
            print(f"çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print()
            print("ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
            print(f"  - è©³ç´°çµæœ: {self.output_dir}/structural_equation_modeling_results.json")
            print(f"  - è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆ: {self.output_dir}/sem_analysis_summary.txt")
            print(f"  - å›³è¡¨: {self.figures_dir}/")
            print()
            print("âš ï¸  é‡è¦: ã“ã®åˆ†æã¯ç‹¬ç«‹ç¾¤æ¯”è¼ƒã§ã‚ã‚Šã€å€‹äººã®å¤‰åŒ–ã¯æ¸¬å®šã—ã¦ã„ã¾ã›ã‚“")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ SEMåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            print(f"è©³ç´°: {traceback.format_exc()}")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_root = Path(__file__).parent.parent.parent
    
    analyzer = StructuralEquationModeling(project_root)
    
    try:
        success = analyzer.run_complete_analysis()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()